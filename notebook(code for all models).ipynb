{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DataSet Analysis**"
      ],
      "metadata": {
        "id": "eeWrdD_ZeWpY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "df = pd.read_csv('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/train.csv')\n",
        "display(df.head())\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4mYDlr0oe0l5",
        "outputId": "294872a8-538c-417d-9120-d1d55a758687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  essay_id                                          full_text  score\n",
              "0  000d118  Many people have car where they live. The thin...      3\n",
              "1  000fe60  I am a scientist at NASA that is discussing th...      3\n",
              "2  001ab80  People always wish they had the same technolog...      4\n",
              "3  001bdc0  We all heard about Venus, the planet without a...      4\n",
              "4  002ba53  Dear, State Senator\\n\\nThis is a letter to arg...      3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5607d06-be2b-4349-ac08-690e393c3420\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000d118</td>\n",
              "      <td>Many people have car where they live. The thin...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000fe60</td>\n",
              "      <td>I am a scientist at NASA that is discussing th...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>001ab80</td>\n",
              "      <td>People always wish they had the same technolog...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>001bdc0</td>\n",
              "      <td>We all heard about Venus, the planet without a...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>002ba53</td>\n",
              "      <td>Dear, State Senator\\n\\nThis is a letter to arg...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5607d06-be2b-4349-ac08-690e393c3420')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e5607d06-be2b-4349-ac08-690e393c3420 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e5607d06-be2b-4349-ac08-690e393c3420');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-80a1c8fb-b28f-41d7-a454-900dee71465f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-80a1c8fb-b28f-41d7-a454-900dee71465f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-80a1c8fb-b28f-41d7-a454-900dee71465f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"essay_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"000fe60\",\n          \"002ba53\",\n          \"001ab80\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"I am a scientist at NASA that is discussing the \\\"face\\\" on mars. I will be explaining how the \\\"face\\\" is a land form. By sharing my information about this isue i will tell you just that.\\n\\nFirst off, how could it be a martions drawing. There is no plant life on mars as of rite now that we know of, which means so far as we know it is not possible for any type of life. That explains how it could not be made by martians. Also why and how would a martion build a face so big. It just does not make any since that a martian did this.\\n\\nNext, why it is a landform. There are many landforms that are weird here in America, and there is also landforms all around the whole Earth. Many of them look like something we can relate to like a snake a turtle a human... So if there are landforms on earth dont you think landforms are on mars to? Of course! why not? It's just unique that the landform on Mars looks like a human face. Also if there was martians and they were trying to get our attention dont you think we would have saw one by now?\\n\\nFinaly, why you should listen to me. You should listen to me because i am a member of NASA and i've been dealing with all of this stuff that were talking about and people who say martians did this have no relation with NASA and have never worked with anything to relate to this landform. One last thing is that everyone working at NASA says the same thing i say, that the \\\"face\\\" is just a landform.\\n\\nTo sum all this up the \\\"face\\\" on mars is a landform but others would like to beleive it's a martian sculpture. Which every one that works at NASA says it's a landform and they are all the ones working on the planet and taking pictures.\",\n          \"Dear, State Senator\\n\\nThis is a letter to argue in favor of keeping the Electoral College.\\\"There are many reasons to keep the Electoral College\\\" one reason is because it is widely regarded as an anachronism, a dispute over the outcome of an Electoral College vote is possible, but it is less likely than a dispute over the popular vote, and the Electoral College restores some of the weight in the political balance that large states (by population) lose by virue of the mal apportionment of the Senate decreed in the Constitution.\\n\\nI am in favor of keeping the Electoral College because,it is widely regarded as an anachronism. A non-democratic method of selecting a president that ought to be [overruled] by declaring the canaditdate who receives the most populare votes the winner. The advocates of this position are correct in arguing that the Electoral College method is not democratic in a method sense.It is the electors who elect the the president ,not the people. But each party selects a slate of electors trusted to vote for the party's nominee (and that trust is rarely betrayed).\\n\\nAnother, reason I am in favor of keeping the Electoral College is because, a dispute over the outcome of an Electoral College vote is possible. But it is less likely than a dispute over the popular vote. But it is less likely than a dispute over the popular vote. The reason is that the winning canadate's share of the Electoral College invariably exceeds his share of the popular vote.\\n\\nLast but not least, I am in favor of keeping the Electoral College is because, the Electoral College restores some of the weight in the political balance that large states (by population) lose by virue of the mal apportionment of the Senate decreed in the Constitution. A larger state gets more attintion from presidential canadidates in a campaign than a small state does. It can be argued that Electoral College methods of selecting the president may turn off potential voters for a canadidates who has no hope of carrying their state. But of  course no voter's vote swings a national election, and in spite of that, about 1/2 the eligible American population did vote in the [2012's] election.\\n\\nFrom, PROPER_NAME            \",\n          \"People always wish they had the same technology that they have seen in movies, or the best new piece of technology that is all over social media. However, nobody seems to think of the risks that these kinds of new technologies may have. Cars have been around for many decades, and now manufacturers are starting to get on the bandwagon and come up with the new and improved technology that they hope will appeal to everyone. As of right now, it seems as though the negative characteristics of these cars consume the positive idea that these manufacturers have tried to convey.\\n\\nCurrently, this new technology in cars has a very long way to go before being completely \\\"driverless\\\". Drivers still need to be on alert when they are driving, as well as control the car near any accidents or complicated traffic situations. This seems to totally defeat the purpose of the \\\"driverless\\\" car. Eventually the technology may improve, but nobody can be certain that the driverless car will eventually become completely \\\"driverless\\\". This idea just seems like a lot of hard work and money for something that is not very neccessary. If someone does not want to drive their car they can just take a city bus or a subway. There are so many options of transportation that can already solve this problem. Even if masnufacturers are trying to make driving more \\\"fun\\\", driving is not meant to be \\\"fun\\\" it is meant to get people where they need to go. Playing around in a car just to have \\\"fun\\\" is just a recipe for disaster.\\n\\nThe idea of the driverless car also raises many questions about who will be liable when someone gets into an accident in one of these new cars. Many states do not even let people drive semi-automatic cars because there are not even laws that pertain to the liability of anyone who get into an accident while driving these type of cars. If these cars become more popular, states may pass new laws. However, this topic also raises questions about who is able to dictate whether or not it was the car or the human's fault for an accident. Since this technology is so new, there could be many problems with the car's system that nobody has even discovered since they have not drove the car themselves. If someone test drives this kind of car or even purchases one and they get into a crash not knowing what could possibly happen to them, they will want to sue the car manufacturer since they were not aware of any bugs in the car's system. These lawsuits can add up and eventually the manufactuers will be in a bunch of debt, which could cost them their whole idea of the driverless car.\\n\\nThe technology car manufacturers are trying to develope may just be a diasaster in the making. There are many alternative options of transportations if you do not feel like driving yourself, and these options are way less expensive than buying a brand new car. Although this technology is relatively new, we can not be certain that this new idea will even pay off in the end, it may just be a waste of money and time. Sometimes the newest technology is not the most benefical.         \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Check the number of unique essay IDs**"
      ],
      "metadata": {
        "id": "ZULX8dYkeidI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_unique_essays = df['essay_id'].nunique()\n",
        "print(f\"Number of unique essays: {num_unique_essays}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_Z2oDIteurU",
        "outputId": "acf47cb6-4e80-41cf-d82f-7565ebb926eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique essays: 17307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Summary statistics of text length**"
      ],
      "metadata": {
        "id": "j4xWo02Gfb-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "df = pd.read_csv('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/train.csv')\n",
        "\n",
        "df['text_length'] = df['full_text'].astype(str).apply(lambda x: len(x.split()))\n",
        "\n",
        "def highlight_rows(row):\n",
        "    if row.name % 2 == 0:\n",
        "        return ['background-color: white'] * len(row)\n",
        "    else:\n",
        "        return ['background-color: lightblue'] * len(row)\n",
        "\n",
        "styled_df = df[['essay_id', 'text_length', 'score']].head(15).style.apply(highlight_rows, axis=1)\n",
        "display(styled_df)\n",
        "\n",
        "styled_stats = df['text_length'].describe().to_frame().style.set_table_styles([\n",
        "    {'selector': 'thead th', 'props': [('background-color', 'black'), ('color', 'white')]}]\n",
        ").applymap(lambda x: 'background-color:lightgreen')\n",
        "\n",
        "print(\"\\nText Length Statistics:\")\n",
        "display(styled_stats)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 872
        },
        "id": "PXbSgFUzfh6A",
        "outputId": "c1ea093a-aee7-450c-f2b7-5e53b599399e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7822d4787510>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_427d7_row0_col0, #T_427d7_row0_col1, #T_427d7_row0_col2, #T_427d7_row2_col0, #T_427d7_row2_col1, #T_427d7_row2_col2, #T_427d7_row4_col0, #T_427d7_row4_col1, #T_427d7_row4_col2, #T_427d7_row6_col0, #T_427d7_row6_col1, #T_427d7_row6_col2, #T_427d7_row8_col0, #T_427d7_row8_col1, #T_427d7_row8_col2, #T_427d7_row10_col0, #T_427d7_row10_col1, #T_427d7_row10_col2, #T_427d7_row12_col0, #T_427d7_row12_col1, #T_427d7_row12_col2, #T_427d7_row14_col0, #T_427d7_row14_col1, #T_427d7_row14_col2 {\n",
              "  background-color: white;\n",
              "}\n",
              "#T_427d7_row1_col0, #T_427d7_row1_col1, #T_427d7_row1_col2, #T_427d7_row3_col0, #T_427d7_row3_col1, #T_427d7_row3_col2, #T_427d7_row5_col0, #T_427d7_row5_col1, #T_427d7_row5_col2, #T_427d7_row7_col0, #T_427d7_row7_col1, #T_427d7_row7_col2, #T_427d7_row9_col0, #T_427d7_row9_col1, #T_427d7_row9_col2, #T_427d7_row11_col0, #T_427d7_row11_col1, #T_427d7_row11_col2, #T_427d7_row13_col0, #T_427d7_row13_col1, #T_427d7_row13_col2 {\n",
              "  background-color: lightblue;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_427d7\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_427d7_level0_col0\" class=\"col_heading level0 col0\" >essay_id</th>\n",
              "      <th id=\"T_427d7_level0_col1\" class=\"col_heading level0 col1\" >text_length</th>\n",
              "      <th id=\"T_427d7_level0_col2\" class=\"col_heading level0 col2\" >score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_427d7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_427d7_row0_col0\" class=\"data row0 col0\" >000d118</td>\n",
              "      <td id=\"T_427d7_row0_col1\" class=\"data row0 col1\" >498</td>\n",
              "      <td id=\"T_427d7_row0_col2\" class=\"data row0 col2\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_427d7_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_427d7_row1_col0\" class=\"data row1 col0\" >000fe60</td>\n",
              "      <td id=\"T_427d7_row1_col1\" class=\"data row1 col1\" >332</td>\n",
              "      <td id=\"T_427d7_row1_col2\" class=\"data row1 col2\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_427d7_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_427d7_row2_col0\" class=\"data row2 col0\" >001ab80</td>\n",
              "      <td id=\"T_427d7_row2_col1\" class=\"data row2 col1\" >550</td>\n",
              "      <td id=\"T_427d7_row2_col2\" class=\"data row2 col2\" >4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_427d7_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_427d7_row3_col0\" class=\"data row3 col0\" >001bdc0</td>\n",
              "      <td id=\"T_427d7_row3_col1\" class=\"data row3 col1\" >451</td>\n",
              "      <td id=\"T_427d7_row3_col2\" class=\"data row3 col2\" >4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_427d7_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_427d7_row4_col0\" class=\"data row4 col0\" >002ba53</td>\n",
              "      <td id=\"T_427d7_row4_col1\" class=\"data row4 col1\" >373</td>\n",
              "      <td id=\"T_427d7_row4_col2\" class=\"data row4 col2\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_427d7_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_427d7_row5_col0\" class=\"data row5 col0\" >0030e86</td>\n",
              "      <td id=\"T_427d7_row5_col1\" class=\"data row5 col1\" >400</td>\n",
              "      <td id=\"T_427d7_row5_col2\" class=\"data row5 col2\" >4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_427d7_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_427d7_row6_col0\" class=\"data row6 col0\" >0033037</td>\n",
              "      <td id=\"T_427d7_row6_col1\" class=\"data row6 col1\" >179</td>\n",
              "      <td id=\"T_427d7_row6_col2\" class=\"data row6 col2\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_427d7_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_427d7_row7_col0\" class=\"data row7 col0\" >0033bf4</td>\n",
              "      <td id=\"T_427d7_row7_col1\" class=\"data row7 col1\" >353</td>\n",
              "      <td id=\"T_427d7_row7_col2\" class=\"data row7 col2\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_427d7_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_427d7_row8_col0\" class=\"data row8 col0\" >0036253</td>\n",
              "      <td id=\"T_427d7_row8_col1\" class=\"data row8 col1\" >310</td>\n",
              "      <td id=\"T_427d7_row8_col2\" class=\"data row8 col2\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_427d7_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_427d7_row9_col0\" class=\"data row9 col0\" >0040e27</td>\n",
              "      <td id=\"T_427d7_row9_col1\" class=\"data row9 col1\" >280</td>\n",
              "      <td id=\"T_427d7_row9_col2\" class=\"data row9 col2\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_427d7_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_427d7_row10_col0\" class=\"data row10 col0\" >004229b</td>\n",
              "      <td id=\"T_427d7_row10_col1\" class=\"data row10 col1\" >178</td>\n",
              "      <td id=\"T_427d7_row10_col2\" class=\"data row10 col2\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_427d7_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_427d7_row11_col0\" class=\"data row11 col0\" >0047cb3</td>\n",
              "      <td id=\"T_427d7_row11_col1\" class=\"data row11 col1\" >192</td>\n",
              "      <td id=\"T_427d7_row11_col2\" class=\"data row11 col2\" >2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_427d7_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_427d7_row12_col0\" class=\"data row12 col0\" >005a72e</td>\n",
              "      <td id=\"T_427d7_row12_col1\" class=\"data row12 col1\" >612</td>\n",
              "      <td id=\"T_427d7_row12_col2\" class=\"data row12 col2\" >4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_427d7_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
              "      <td id=\"T_427d7_row13_col0\" class=\"data row13 col0\" >00613e3</td>\n",
              "      <td id=\"T_427d7_row13_col1\" class=\"data row13 col1\" >393</td>\n",
              "      <td id=\"T_427d7_row13_col2\" class=\"data row13 col2\" >3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_427d7_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
              "      <td id=\"T_427d7_row14_col0\" class=\"data row14 col0\" >0065bd6</td>\n",
              "      <td id=\"T_427d7_row14_col1\" class=\"data row14 col1\" >286</td>\n",
              "      <td id=\"T_427d7_row14_col2\" class=\"data row14 col2\" >3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Text Length Statistics:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-2982337e3eda>:26: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.\n",
            "  ).applymap(lambda x: 'background-color:lightgreen')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7822d34cb610>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_4970f thead th {\n",
              "  background-color: black;\n",
              "  color: white;\n",
              "}\n",
              "#T_4970f_row0_col0, #T_4970f_row1_col0, #T_4970f_row2_col0, #T_4970f_row3_col0, #T_4970f_row4_col0, #T_4970f_row5_col0, #T_4970f_row6_col0, #T_4970f_row7_col0 {\n",
              "  background-color: lightgreen;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_4970f\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_4970f_level0_col0\" class=\"col_heading level0 col0\" >text_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_4970f_level0_row0\" class=\"row_heading level0 row0\" >count</th>\n",
              "      <td id=\"T_4970f_row0_col0\" class=\"data row0 col0\" >17307.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4970f_level0_row1\" class=\"row_heading level0 row1\" >mean</th>\n",
              "      <td id=\"T_4970f_row1_col0\" class=\"data row1 col0\" >368.348241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4970f_level0_row2\" class=\"row_heading level0 row2\" >std</th>\n",
              "      <td id=\"T_4970f_row2_col0\" class=\"data row2 col0\" >150.394776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4970f_level0_row3\" class=\"row_heading level0 row3\" >min</th>\n",
              "      <td id=\"T_4970f_row3_col0\" class=\"data row3 col0\" >150.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4970f_level0_row4\" class=\"row_heading level0 row4\" >25%</th>\n",
              "      <td id=\"T_4970f_row4_col0\" class=\"data row4 col0\" >253.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4970f_level0_row5\" class=\"row_heading level0 row5\" >50%</th>\n",
              "      <td id=\"T_4970f_row5_col0\" class=\"data row5 col0\" >345.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4970f_level0_row6\" class=\"row_heading level0 row6\" >75%</th>\n",
              "      <td id=\"T_4970f_row6_col0\" class=\"data row6 col0\" >452.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_4970f_level0_row7\" class=\"row_heading level0 row7\" >max</th>\n",
              "      <td id=\"T_4970f_row7_col0\" class=\"data row7 col0\" >1656.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Plot a bar chart of score distribution**"
      ],
      "metadata": {
        "id": "kz2P_phngN6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x=df['score'], palette='viridis')\n",
        "plt.xlabel(\"Essay Score\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.title(\"Distribution of Essay Scores\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "IUkP2NZDgRwJ",
        "outputId": "b5db6af6-c4eb-40c4-ee3d-eb85e8868f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-81e4818b85d9>:5: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  sns.countplot(x=df['score'], palette='viridis')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Models Usage**\n",
        "\n",
        "**LinearRegression**\n",
        "\n",
        "\n",
        "**XGBRegreesor**\n",
        "\n",
        "**LSTM**\n",
        "\n",
        "**LGBM**\n",
        "\n",
        "**BERT**"
      ],
      "metadata": {
        "id": "lH2mKFIYg5OV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**M1. Linear Regression**"
      ],
      "metadata": {
        "id": "2Jy8N-99h2GN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbA7drmrqwNj",
        "outputId": "a15dbc97-5f04-4c9d-ecbd-1146ac615d4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quadratic Weighted Kappa (Kappa): 0.6537444455043804\n",
            "Model saved as /content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/model.h5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import joblib\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load your train.csv data\n",
        "df = pd.read_csv('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/train.csv')\n",
        "\n",
        "# Download NLTK resource (if not already downloaded)\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Define function for text preprocessing\n",
        "def preprocess_text(text):\n",
        "    # Remove non-alphanumeric characters and extra spaces\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenization using NLTK\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Join tokens back into string\n",
        "    preprocessed_text = ' '.join(filtered_tokens)\n",
        "\n",
        "    return preprocessed_text\n",
        "\n",
        "# Apply preprocessing function to 'full_text' column\n",
        "df['clean_text'] = df['full_text'].apply(preprocess_text)\n",
        "\n",
        "# Initialize TF-IDF Vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)  # Adjust max_features as needed\n",
        "\n",
        "# Fit and transform the cleaned text\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(df['clean_text'])\n",
        "\n",
        "# Split data into training and validation sets (80-20 split)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(tfidf_matrix, df['score'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Linear Regression model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "y_pred = model.predict(X_valid)\n",
        "\n",
        "# Clip predictions to range [1, 5] as scores are typically in this range\n",
        "y_pred = np.clip(y_pred, 1, 5)\n",
        "\n",
        "# Calculate quadratic weighted kappa\n",
        "kappa = cohen_kappa_score(y_valid.round().astype(int), y_pred.round().astype(int), weights='quadratic')\n",
        "\n",
        "print(f\"Quadratic Weighted Kappa (Kappa): {kappa}\")\n",
        "\n",
        "# Save the model to Google Drive as HDF5 file\n",
        "model_filename = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/model.h5'\n",
        "joblib.dump(model, model_filename)\n",
        "print(f\"Model saved as {model_filename}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTfLSvuGuUs7",
        "outputId": "32754b64-f6ee-4bf7-9cec-79c932274f4a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission file saved as /content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/submission.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load test data\n",
        "test_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/test.csv'\n",
        "df_test = pd.read_csv(test_path)\n",
        "\n",
        "# Load the saved model and vectorizer\n",
        "model = joblib.load('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/essaymodel.h5')\n",
        "tfidf_vectorizer = joblib.load('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/tfidf_vectorizer.joblib')\n",
        "\n",
        "# Define function for text preprocessing\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    preprocessed_text = ' '.join(filtered_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Apply preprocessing function to 'full_text' column\n",
        "df_test['clean_text'] = df_test['full_text'].apply(preprocess_text)\n",
        "\n",
        "# Transform the cleaned text using the loaded TF-IDF vectorizer\n",
        "tfidf_matrix_test = tfidf_vectorizer.transform(df_test['clean_text'])\n",
        "\n",
        "# Predict on the test dataset\n",
        "test_predictions = model.predict(tfidf_matrix_test)\n",
        "test_predictions = np.clip(test_predictions, 1, 6)  # Clip predictions to range [1, 6]\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'essay_id': df_test['essay_id'],\n",
        "    'score': test_predictions.round().astype(int)\n",
        "})\n",
        "\n",
        "# Save the submission file\n",
        "submission_filename = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/submission.csv'\n",
        "submission.to_csv(submission_filename, index=False)\n",
        "print(f\"Submission file saved as {submission_filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTtIzoYv2w8T"
      },
      "source": [
        "#**M2. XGB Regressor**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpyCDUdu2ypL",
        "outputId": "803abd57-0efb-4dfa-dfe2-ef12c9da05c6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation RMSE: 0.6817568834285783\n",
            "Validation Quadratic Weighted Kappa (Kappa): 0.7120387905786805\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, cohen_kappa_score\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load training data\n",
        "train_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/train.csv'\n",
        "df_train = pd.read_csv(train_path)\n",
        "\n",
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    preprocessed_text = ' '.join(filtered_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Apply preprocessing to 'full_text' column\n",
        "df_train['clean_text'] = df_train['full_text'].apply(preprocess_text)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X = tfidf_vectorizer.fit_transform(df_train['clean_text'])\n",
        "y = df_train['score']\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize XGBoost model\n",
        "model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "y_valid_pred = model.predict(X_valid)\n",
        "y_valid_pred = np.clip(y_valid_pred, 1, 6)  # Clip predictions to range [1, 6]\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "valid_rmse = np.sqrt(mean_squared_error(y_valid, y_valid_pred))\n",
        "valid_kappa = cohen_kappa_score(y_valid.round().astype(int), y_valid_pred.round().astype(int), weights='quadratic')\n",
        "\n",
        "print(f\"Validation RMSE: {valid_rmse}\")\n",
        "print(f\"Validation Quadratic Weighted Kappa (Kappa): {valid_kappa}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXxvRPqI2wkX",
        "outputId": "e0c1b1ce-8cfe-47c8-fd58-c75780fe3983"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission file saved as /content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/submission2.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load test data\n",
        "test_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/test.csv'\n",
        "df_test = pd.read_csv(test_path)\n",
        "\n",
        "# Load the saved model and vectorizer\n",
        "model = joblib.load('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/essaymodel.h5')\n",
        "tfidf_vectorizer = joblib.load('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/tfidf_vectorizer.joblib')\n",
        "\n",
        "# Define function for text preprocessing\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    preprocessed_text = ' '.join(filtered_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Apply preprocessing function to 'full_text' column\n",
        "df_test['clean_text'] = df_test['full_text'].apply(preprocess_text)\n",
        "\n",
        "# Transform the cleaned text using the loaded TF-IDF vectorizer\n",
        "tfidf_matrix_test = tfidf_vectorizer.transform(df_test['clean_text'])\n",
        "\n",
        "# Predict on the test dataset\n",
        "test_predictions = model.predict(tfidf_matrix_test)\n",
        "test_predictions = np.clip(test_predictions, 1, 6)  # Clip predictions to range [1, 6]\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'essay_id': df_test['essay_id'],\n",
        "    'score': test_predictions.round().astype(int)\n",
        "})\n",
        "\n",
        "# Save the submission file\n",
        "submission_filename = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/submission2.csv'\n",
        "submission.to_csv(submission_filename, index=False)\n",
        "print(f\"Submission file saved as {submission_filename}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ICEH2RvHRHz"
      },
      "source": [
        "#**M3.NN**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0vvAUgEeljo"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchtext transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXvKbKEIfbMx",
        "outputId": "ef48c952-f1d7-4f6f-c572-a08f42206ad9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 0.946622303594076\n",
            "Epoch 2/5, Loss: 0.6983935279623638\n",
            "Epoch 3/5, Loss: 0.6179481594687304\n",
            "Epoch 4/5, Loss: 0.5646644185250711\n",
            "Epoch 5/5, Loss: 0.5179007470921068\n",
            "RMSE: 0.5831318874974849\n",
            "Quadratic Weighted Kappa (Kappa): 0.7821262219124349\n",
            "Accuracy: 0.6270873057144508\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, cohen_kappa_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Assuming preprocess_text function and train.csv loading are defined as before\n",
        "# Replace with your actual implementations if different\n",
        "class EssayDataset(Dataset):\n",
        "    def __init__(self, texts, scores, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.scores = scores\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        score = float(self.scores[idx])\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = inputs['input_ids'].squeeze(0)\n",
        "        attention_mask = inputs['attention_mask'].squeeze(0)\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'score': torch.tensor(score, dtype=torch.float)\n",
        "        }\n",
        "class CNNTextClassifier(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_filters, filter_sizes, output_dim, dropout):\n",
        "        super(CNNTextClassifier, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(len(tokenizer), embedding_dim)\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(fs, embedding_dim))\n",
        "            for fs in filter_sizes\n",
        "        ])\n",
        "        self.fc = nn.Linear(num_filters * len(filter_sizes), output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        embedded = self.embedding(input_ids)\n",
        "        embedded = embedded.unsqueeze(1)  # add channel dimension (batch_size, channels, seq_len, embed_dim)\n",
        "\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]  # convolution over embedding\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]  # max-pooling over time\n",
        "        cat = self.dropout(torch.cat(pooled, dim=1))  # concatenate pooled layers\n",
        "\n",
        "        return self.fc(cat)\n",
        "# Hyperparameters\n",
        "MAX_LEN = 512\n",
        "EMBEDDING_DIM = 100\n",
        "NUM_FILTERS = 100\n",
        "FILTER_SIZES = [3, 4, 5]\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0.5\n",
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 8\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Data preparation\n",
        "train_dataset = EssayDataset(df_train['clean_text'].tolist(), df_train['score'].tolist(), tokenizer, MAX_LEN)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# Model initialization\n",
        "model = CNNTextClassifier(EMBEDDING_DIM, NUM_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n",
        "\n",
        "# Optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Training loop\n",
        "model.train()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        scores = batch['score']\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs.squeeze(1), scores)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {epoch_loss / len(train_loader)}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        scores = batch['score']\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        predictions.extend(outputs.squeeze(1).tolist())\n",
        "        true_labels.extend(scores.tolist())\n",
        "\n",
        "predictions = np.array(predictions)\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "rmse = np.sqrt(mean_squared_error(true_labels, predictions))\n",
        "kappa = cohen_kappa_score(true_labels.round().astype(int), predictions.round().astype(int), weights='quadratic')\n",
        "accuracy = accuracy_score(true_labels.round().astype(int), predictions.round().astype(int))\n",
        "\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"Quadratic Weighted Kappa (Kappa): {kappa}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/cnn_model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEkq-WVL0hLn",
        "outputId": "be158024-4be7-4b9c-ffd2-1eee02d42044"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions saved successfully to submission.csv.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import mean_squared_error, cohen_kappa_score, accuracy_score\n",
        "\n",
        "# Define EssayDataset class\n",
        "class EssayDataset(Dataset):\n",
        "    def __init__(self, texts, scores, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.scores = scores  # Dummy scores for test set\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = inputs['input_ids'].squeeze(0)\n",
        "        attention_mask = inputs['attention_mask'].squeeze(0)\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask\n",
        "        }\n",
        "\n",
        "# Define CNNTextClassifier class\n",
        "class CNNTextClassifier(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_filters, filter_sizes, output_dim, dropout, vocab_size):\n",
        "        super(CNNTextClassifier, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(fs, embedding_dim))\n",
        "            for fs in filter_sizes\n",
        "        ])\n",
        "        self.fc = nn.Linear(num_filters * len(filter_sizes), output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        embedded = self.embedding(input_ids)\n",
        "        embedded = embedded.unsqueeze(1)  # add channel dimension (batch_size, channels, seq_len, embed_dim)\n",
        "\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]  # convolution over embedding\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]  # max-pooling over time\n",
        "        cat = self.dropout(torch.cat(pooled, dim=1))  # concatenate pooled layers\n",
        "\n",
        "        return self.fc(cat)\n",
        "\n",
        "# Hyperparameters\n",
        "MAX_LEN = 512\n",
        "EMBEDDING_DIM = 100\n",
        "NUM_FILTERS = 100\n",
        "FILTER_SIZES = [3, 4, 5]\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0.5\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load test data\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/test.csv')\n",
        "test_df['clean_text'] = test_df['full_text'].astype(str)  # Assuming 'full_text' is already cleaned if needed\n",
        "\n",
        "# Create test dataset and data loader\n",
        "test_dataset = EssayDataset(test_df['clean_text'].tolist(),\n",
        "                            [0]*len(test_df),  # Dummy scores since we predict these\n",
        "                            tokenizer,\n",
        "                            MAX_LEN)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Initialize model\n",
        "model = CNNTextClassifier(EMBEDDING_DIM, NUM_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, len(tokenizer))\n",
        "\n",
        "# Load trained model state dict\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/cnn_model.pt'))\n",
        "\n",
        "# Evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Predictions storage\n",
        "predictions = []\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        predictions.extend(outputs.squeeze(1).tolist())\n",
        "\n",
        "# Convert predictions to numpy array\n",
        "predictions = np.array(predictions)\n",
        "\n",
        "# Prepare submission DataFrame\n",
        "submission_df = pd.DataFrame({\n",
        "    'essay_id': test_df['essay_id'],\n",
        "    'score': predictions\n",
        "})\n",
        "\n",
        "# Save submission file\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved successfully to submission.csv.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nttSNVux1J3f",
        "outputId": "f785b5c6-3026-4f35-b304-e56f10329472"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions saved successfully to submission2.csv.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import mean_squared_error, cohen_kappa_score, accuracy_score\n",
        "\n",
        "# Define EssayDataset class\n",
        "class EssayDataset(Dataset):\n",
        "    def __init__(self, texts, scores, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.scores = scores  # Dummy scores for test set\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = inputs['input_ids'].squeeze(0)\n",
        "        attention_mask = inputs['attention_mask'].squeeze(0)\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask\n",
        "        }\n",
        "\n",
        "# Define CNNTextClassifier class\n",
        "class CNNTextClassifier(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_filters, filter_sizes, output_dim, dropout, vocab_size):\n",
        "        super(CNNTextClassifier, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(fs, embedding_dim))\n",
        "            for fs in filter_sizes\n",
        "        ])\n",
        "        self.fc = nn.Linear(num_filters * len(filter_sizes), output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        embedded = self.embedding(input_ids)\n",
        "        embedded = embedded.unsqueeze(1)  # add channel dimension (batch_size, channels, seq_len, embed_dim)\n",
        "\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]  # convolution over embedding\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]  # max-pooling over time\n",
        "        cat = self.dropout(torch.cat(pooled, dim=1))  # concatenate pooled layers\n",
        "\n",
        "        return self.fc(cat)\n",
        "\n",
        "# Hyperparameters\n",
        "MAX_LEN = 512\n",
        "EMBEDDING_DIM = 100\n",
        "NUM_FILTERS = 100\n",
        "FILTER_SIZES = [3, 4, 5]\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0.5\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load test data\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/test.csv')\n",
        "test_df['clean_text'] = test_df['full_text'].astype(str)  # Assuming 'full_text' is already cleaned if needed\n",
        "\n",
        "# Create test dataset and data loader\n",
        "test_dataset = EssayDataset(test_df['clean_text'].tolist(),\n",
        "                            [0]*len(test_df),  # Dummy scores since we predict these\n",
        "                            tokenizer,\n",
        "                            MAX_LEN)\n",
        "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "\n",
        "# Initialize model\n",
        "model = CNNTextClassifier(EMBEDDING_DIM, NUM_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, len(tokenizer))\n",
        "\n",
        "# Load trained model state dict\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/cnn_model.pt'))\n",
        "\n",
        "# Evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Predictions storage\n",
        "predictions = []\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        predictions.extend(outputs.squeeze(1).tolist())\n",
        "\n",
        "# Convert predictions to numpy array\n",
        "predictions = np.array(predictions)\n",
        "\n",
        "# Prepare submission DataFrame\n",
        "submission_df = pd.DataFrame({\n",
        "    'essay_id': test_df['essay_id'],\n",
        "    'score': predictions\n",
        "})\n",
        "\n",
        "# Save submission file to specified path\n",
        "submission_df.to_csv('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/submission4.csv', index=False)\n",
        "\n",
        "print(\"Predictions saved successfully to submission2.csv.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLWd3bWRAqBe"
      },
      "source": [
        "#**M4 LGBM**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Czq4pyi0ArW0",
        "outputId": "e6f24f8a-17f6-4244-c0bd-84e9b9d3b0ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.055914 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 210644\n",
            "[LightGBM] [Info] Number of data points in the train set: 13845, number of used features: 1000\n",
            "[LightGBM] [Info] Start training from score 2.953702\n",
            "Validation RMSE: 0.6497080013551857\n",
            "Validation Quadratic Weighted Kappa (Kappa): 0.725457247984968\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/AutomatedEssaymodel_LightGBM.h5']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.metrics import mean_squared_error, cohen_kappa_score\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import joblib\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load training data\n",
        "train_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/train.csv'\n",
        "df_train = pd.read_csv(train_path)\n",
        "\n",
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    preprocessed_text = ' '.join(filtered_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Apply preprocessing to 'full_text' column\n",
        "df_train['clean_text'] = df_train['full_text'].apply(preprocess_text)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X = tfidf_vectorizer.fit_transform(df_train['clean_text'])\n",
        "y = df_train['score']\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize LightGBM model\n",
        "model = LGBMRegressor(random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on validation set\n",
        "y_valid_pred = model.predict(X_valid)\n",
        "y_valid_pred = np.clip(y_valid_pred, 1, 6)  # Clip predictions to range [1, 6]\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "valid_rmse = np.sqrt(mean_squared_error(y_valid, y_valid_pred))\n",
        "valid_kappa = cohen_kappa_score(y_valid.round().astype(int), y_valid_pred.round().astype(int), weights='quadratic')\n",
        "\n",
        "print(f\"Validation RMSE: {valid_rmse}\")\n",
        "print(f\"Validation Quadratic Weighted Kappa (Kappa): {valid_kappa}\")\n",
        "\n",
        "# Save the model\n",
        "model_save_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/AutomatedEssaymodel_LightGBM.h5'\n",
        "joblib.dump(model, model_save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ii4BIn1mA1Tl",
        "outputId": "57ede020-b695-48a7-c6c9-eb91b9c1db24"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission file saved as /content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/submission_lightgbm.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load test data\n",
        "test_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/test.csv'\n",
        "df_test = pd.read_csv(test_path)\n",
        "\n",
        "# Load the saved model and vectorizer\n",
        "model = joblib.load('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/AutomatedEssaymodel_LightGBM.h5')\n",
        "tfidf_vectorizer = joblib.load('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/tfidf_vectorizer.joblib')\n",
        "\n",
        "# Define function for text preprocessing\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    preprocessed_text = ' '.join(filtered_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Apply preprocessing function to 'full_text' column\n",
        "df_test['clean_text'] = df_test['full_text'].apply(preprocess_text)\n",
        "\n",
        "# Transform the cleaned text using the loaded TF-IDF vectorizer\n",
        "tfidf_matrix_test = tfidf_vectorizer.transform(df_test['clean_text'])\n",
        "\n",
        "# Predict on the test dataset\n",
        "test_predictions = model.predict(tfidf_matrix_test)\n",
        "test_predictions = np.clip(test_predictions, 1, 6)  # Clip predictions to range [1, 6]\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({\n",
        "    'essay_id': df_test['essay_id'],\n",
        "    'score': test_predictions.round().astype(int)\n",
        "})\n",
        "\n",
        "# Save the submission file\n",
        "submission_filename = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/submission_lightgbm.csv'\n",
        "submission.to_csv(submission_filename, index=False)\n",
        "print(f\"Submission file saved as {submission_filename}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xt0dRUDbWyHJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOIyjbVYQpOt"
      },
      "source": [
        "#**M2. imporved XGBR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxAyGCV4S4AI",
        "outputId": "b25fa4f8-46fd-4b7f-df92-f7a294f25c89"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best parameters: {'subsample': 0.8, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
            "Validation RMSE: 0.6114738808268803\n",
            "Validation Quadratic Weighted Kappa: 0.7665171631265701\n",
            "Model saved to /content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/Model.h5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, cohen_kappa_score\n",
        "import joblib\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load training data\n",
        "train_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/train.csv'\n",
        "df_train = pd.read_csv(train_path)\n",
        "\n",
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    preprocessed_text = ' '.join(filtered_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Apply preprocessing to 'full_text' column\n",
        "df_train['clean_text'] = df_train['full_text'].apply(preprocess_text)\n",
        "\n",
        "# Add additional features\n",
        "df_train['text_length'] = df_train['full_text'].apply(len)\n",
        "df_train['word_count'] = df_train['full_text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df_train['clean_text'])\n",
        "\n",
        "# Combine TF-IDF features with additional features\n",
        "X = np.hstack((X_tfidf.toarray(), df_train[['text_length', 'word_count']].values))\n",
        "y = df_train['score']\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for RandomizedSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# Setup the random search with 5-fold cross-validation\n",
        "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_grid, n_iter=50, scoring='neg_mean_squared_error', cv=5, verbose=1, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = random_search.best_params_\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "# Train the model with the best parameters\n",
        "best_xgb_model = XGBRegressor(**best_params)\n",
        "best_xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_valid_pred = best_xgb_model.predict(X_valid)\n",
        "y_valid_pred = np.clip(y_valid_pred, 1, 6)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "valid_rmse = np.sqrt(mean_squared_error(y_valid, y_valid_pred))\n",
        "valid_kappa = cohen_kappa_score(y_valid.round().astype(int), y_valid_pred.round().astype(int), weights='quadratic')\n",
        "\n",
        "print(f\"Validation RMSE: {valid_rmse}\")\n",
        "print(f\"Validation Quadratic Weighted Kappa: {valid_kappa}\")\n",
        "\n",
        "# Save the model to a file\n",
        "model_save_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/Model.h5'\n",
        "joblib.dump(best_xgb_model, model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYsOZmInFrT4",
        "outputId": "c5cb6155-5e1d-4e97-a176-46ea4ed04617"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission saved to /content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/submissions.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from xgboost import XGBRegressor\n",
        "import joblib\n",
        "\n",
        "# Download NLTK resources (if not already downloaded)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load test data\n",
        "test_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/test.csv'\n",
        "df_test = pd.read_csv(test_path)\n",
        "\n",
        "# Text preprocessing function (same as used for training data)\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    preprocessed_text = ' '.join(filtered_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Apply preprocessing to 'full_text' column in test data\n",
        "df_test['clean_text'] = df_test['full_text'].apply(preprocess_text)\n",
        "\n",
        "# Load the trained TF-IDF vectorizer\n",
        "vectorizer_load_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/tfidf_vectorizer.pkl'\n",
        "tfidf_vectorizer = joblib.load(vectorizer_load_path)\n",
        "\n",
        "# TF-IDF Vectorization on test data\n",
        "X_tfidf_test = tfidf_vectorizer.transform(df_test['clean_text'])\n",
        "\n",
        "# Additional features for test data\n",
        "df_test['text_length'] = df_test['full_text'].apply(len)\n",
        "df_test['word_count'] = df_test['full_text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Combine TF-IDF features with additional features\n",
        "X_test = np.hstack((X_tfidf_test.toarray(), df_test[['text_length', 'word_count']].values))\n",
        "\n",
        "# Load the trained XGBoost model\n",
        "model_load_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/Model.h5'\n",
        "best_xgb_model = joblib.load(model_load_path)\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_pred = best_xgb_model.predict(X_test)\n",
        "y_test_pred = np.clip(y_test_pred, 1, 6)  # Clip predictions to the range [1, 6]\n",
        "\n",
        "# Prepare submission DataFrame\n",
        "submission_df = pd.DataFrame({'essay_id': df_test['essay_id'], 'predicted_score': y_test_pred})\n",
        "\n",
        "# Save submission to CSV file\n",
        "submission_save_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/submissions.csv'\n",
        "submission_df.to_csv(submission_save_path, index=False)\n",
        "print(f\"Submission saved to {submission_save_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSn46kc8K5hi"
      },
      "source": [
        "**M5. LSTM model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUKIO_2kK8Jf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, cohen_kappa_score\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, SpatialDropout1D, Bidirectional, Concatenate, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import joblib\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load training data\n",
        "train_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/train.csv'\n",
        "df_train = pd.read_csv(train_path)\n",
        "\n",
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    preprocessed_text = ' '.join(filtered_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Apply preprocessing to 'full_text' column\n",
        "df_train['clean_text'] = df_train['full_text'].apply(preprocess_text)\n",
        "\n",
        "# Tokenization and padding\n",
        "tokenizer = Tokenizer(num_words=5000, lower=True)\n",
        "tokenizer.fit_on_texts(df_train['clean_text'].values)\n",
        "X = tokenizer.texts_to_sequences(df_train['clean_text'].values)\n",
        "X = pad_sequences(X, maxlen=300)\n",
        "\n",
        "# Save the tokenizer\n",
        "tokenizer_save_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/tokenizer.pkl'\n",
        "joblib.dump(tokenizer, tokenizer_save_path)\n",
        "\n",
        "# Additional features\n",
        "df_train['text_length'] = df_train['full_text'].apply(len)\n",
        "df_train['word_count'] = df_train['full_text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Labels\n",
        "y = df_train['score'].values\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train_text, X_valid_text, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train_additional, X_valid_additional = train_test_split(df_train[['text_length', 'word_count']].values, test_size=0.2, random_state=42)\n",
        "\n",
        "# Building the LSTM model with additional features\n",
        "embedding_dim = 100\n",
        "\n",
        "# Text input branch\n",
        "text_input = Input(shape=(300,), name='text_input')\n",
        "x = Embedding(input_dim=5000, output_dim=embedding_dim, input_length=300)(text_input)\n",
        "x = SpatialDropout1D(0.2)(x)\n",
        "x = Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2))(x)\n",
        "\n",
        "# Additional features input branch\n",
        "additional_input = Input(shape=(2,), name='additional_input')\n",
        "y = Dense(10, activation='relu')(additional_input)\n",
        "\n",
        "# Concatenate the two branches\n",
        "combined = Concatenate()([x, y])\n",
        "combined = Dense(50, activation='relu')(combined)\n",
        "combined = Dropout(0.2)(combined)\n",
        "output = Dense(1, activation='linear')(combined)\n",
        "\n",
        "model = Model(inputs=[text_input, additional_input], outputs=output)\n",
        "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
        "print(model.summary())\n",
        "\n",
        "# Training the model\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
        "history = model.fit([X_train_text, X_train_additional], y_train, epochs=20, batch_size=64, validation_data=([X_valid_text, X_valid_additional], y_valid), callbacks=[early_stopping], verbose=1)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_valid_pred = model.predict([X_valid_text, X_valid_additional])\n",
        "y_valid_pred = np.clip(y_valid_pred, 1, 6).flatten()\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "valid_rmse = np.sqrt(mean_squared_error(y_valid, y_valid_pred))\n",
        "valid_kappa = cohen_kappa_score(y_valid.round().astype(int), y_valid_pred.round().astype(int), weights='quadratic')\n",
        "\n",
        "print(f\"Validation RMSE: {valid_rmse}\")\n",
        "print(f\"Validation Quadratic Weighted Kappa: {valid_kappa}\")\n",
        "\n",
        "# Save the model to a file\n",
        "model_save_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/LSTM_Model.h5'\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXgkYY6hSoZK",
        "outputId": "76497220-79b6-44ee-a948-317481b035b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x796bb198fac0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "Submission saved to /content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/submission100.csv\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import load_model\n",
        "import joblib\n",
        "\n",
        "# Download NLTK resources (if not already downloaded)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function for text preprocessing (same as used in training)\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    preprocessed_text = ' '.join(filtered_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Load test data\n",
        "test_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/test.csv'\n",
        "df_test = pd.read_csv(test_path)\n",
        "\n",
        "# Apply preprocessing to 'full_text' column in test data\n",
        "df_test['clean_text'] = df_test['full_text'].apply(preprocess_text)\n",
        "\n",
        "# Load the trained tokenizer\n",
        "tokenizer_load_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/tokenizer.pkl'\n",
        "tokenizer = joblib.load(tokenizer_load_path)\n",
        "\n",
        "# Tokenization and padding for test data\n",
        "X_test = tokenizer.texts_to_sequences(df_test['clean_text'].values)\n",
        "X_test = pad_sequences(X_test, maxlen=300)\n",
        "\n",
        "# Load the trained LSTM model\n",
        "model_load_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/LSTM_Model.h5'\n",
        "model = load_model(model_load_path)\n",
        "\n",
        "# Additional features for test data\n",
        "df_test['text_length'] = df_test['full_text'].apply(len)\n",
        "df_test['word_count'] = df_test['full_text'].apply(lambda x: len(x.split()))\n",
        "X_test_additional = df_test[['text_length', 'word_count']].values\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_pred = model.predict([X_test, X_test_additional])\n",
        "y_test_pred = np.clip(y_test_pred, 1, 6).flatten()\n",
        "y_test_pred = np.round(y_test_pred).astype(int)  # Round predictions and convert to integers\n",
        "\n",
        "# Prepare submission DataFrame\n",
        "submission_df = pd.DataFrame({'essay_id': df_test['essay_id'], 'predicted_score': y_test_pred})\n",
        "\n",
        "# Save submission to CSV file\n",
        "submission_save_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/submission100.csv'\n",
        "submission_df.to_csv(submission_save_path, index=False)\n",
        "print(f\"Submission saved to {submission_save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPsWeLsrliR4",
        "outputId": "fdd82ebd-bbd3-4eb1-a27b-d89debbb45ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspellchecker\n",
            "  Downloading pyspellchecker-0.8.1-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.8.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspellchecker\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDPEuS_Nl7Ic"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from xgboost import XGBRegressor\n",
        "import joblib\n",
        "from spellchecker import SpellChecker  # Ensure you have installed 'pyspellchecker' package\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Spell checker setup\n",
        "spell = SpellChecker()\n",
        "\n",
        "# Text preprocessing function with spell checking\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove special characters and numbers\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.lower()\n",
        "\n",
        "    # Spell checking\n",
        "    tokens = word_tokenize(text)\n",
        "    corrected_tokens = [spell.correction(word) for word in tokens]\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in corrected_tokens if word not in stop_words]\n",
        "    preprocessed_text = ' '.join(filtered_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Load test data\n",
        "test_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/test.csv'\n",
        "df_test = pd.read_csv(test_path)\n",
        "\n",
        "# Apply preprocessing to 'full_text' column in test data\n",
        "df_test['clean_text'] = df_test['full_text'].apply(preprocess_text)\n",
        "\n",
        "# Load TF-IDF vectorizer\n",
        "vectorizer_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/Tfidf_Vectorizer.joblib'\n",
        "tfidf_vectorizer = joblib.load(vectorizer_path)\n",
        "\n",
        "# Transform test data using TF-IDF vectorizer\n",
        "X_tfidf_test = tfidf_vectorizer.transform(df_test['clean_text'])\n",
        "\n",
        "# Additional features for test data\n",
        "df_test['text_length'] = df_test['full_text'].apply(len)\n",
        "df_test['word_count'] = df_test['full_text'].apply(lambda x: len(x.split()))\n",
        "\n",
        "# Combine TF-IDF features and additional features\n",
        "X_test_features = np.hstack((X_tfidf_test.toarray(), df_test[['text_length', 'word_count']].values))\n",
        "\n",
        "# Load the trained XGBoost model\n",
        "model_load_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/XGBModel.h5'\n",
        "xgb_model = joblib.load(model_load_path)\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_pred = xgb_model.predict(X_test_features)\n",
        "y_test_pred = np.clip(y_test_pred, 1, 6)  # Clip predictions to the range [1, 6]\n",
        "\n",
        "# Prepare submission DataFrame\n",
        "submission_df = pd.DataFrame({'essay_id': df_test['essay_id'], 'predicted_score': y_test_pred})\n",
        "\n",
        "# Save submission to CSV file\n",
        "submission_save_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/submissions_xgb.csv'\n",
        "submission_df.to_csv(submission_save_path, index=False)\n",
        "print(f\"Submission saved to {submission_save_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDMFFJVav1sr"
      },
      "source": [
        "#**M2 imporved XGBR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsU7aAoBydq6",
        "outputId": "0b66800c-65d3-41ff-b1ab-420191080731"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
            "Best parameters: {'subsample': 0.8, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.1, 'colsample_bytree': 1.0}\n",
            "Validation RMSE: 0.6100873455112498\n",
            "Validation Quadratic Weighted Kappa: 0.7711302104617234\n",
            "Model saved to /content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/XGBR-Model.h5\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, cohen_kappa_score\n",
        "import joblib\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load training data\n",
        "train_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/train.csv'\n",
        "df_train = pd.read_csv(train_path)\n",
        "\n",
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    preprocessed_text = ' '.join(filtered_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Apply preprocessing to 'full_text' column\n",
        "df_train['clean_text'] = df_train['full_text'].apply(preprocess_text)\n",
        "\n",
        "# Add additional features (excluding avg_sentence_length and flesch_reading_ease)\n",
        "df_train['text_length'] = df_train['full_text'].apply(len)\n",
        "df_train['word_count'] = df_train['full_text'].apply(lambda x: len(x.split()))\n",
        "df_train['avg_word_length'] = df_train['full_text'].apply(lambda x: np.mean([len(word) for word in x.split()]))\n",
        "df_train['sentence_count'] = df_train['full_text'].apply(lambda x: len(re.split(r'[.!?]', x)))\n",
        "\n",
        "# TF-IDF Vectorization with bi-grams and reduced max_features\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=500, ngram_range=(1, 2))\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df_train['clean_text'])\n",
        "\n",
        "# Save the TF-IDF vectorizer\n",
        "vectorizer_save_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/xgbrtfidf_vectorizer.joblib'\n",
        "joblib.dump(tfidf_vectorizer, vectorizer_save_path)\n",
        "\n",
        "# Combine TF-IDF features with selected additional features\n",
        "X = np.hstack((X_tfidf.toarray(), df_train[['text_length', 'word_count', 'avg_word_length', 'sentence_count']].values))\n",
        "y = df_train['score']\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for RandomizedSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# Setup the random search with 5-fold cross-validation\n",
        "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_grid, n_iter=50, scoring='neg_mean_squared_error', cv=5, verbose=1, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = random_search.best_params_\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "# Train the model with the best parameters\n",
        "best_xgb_model = XGBRegressor(**best_params)\n",
        "best_xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_valid_pred = best_xgb_model.predict(X_valid)\n",
        "y_valid_pred = np.clip(y_valid_pred, 1, 6)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "valid_rmse = np.sqrt(mean_squared_error(y_valid, y_valid_pred))\n",
        "valid_kappa = cohen_kappa_score(y_valid.round().astype(int), y_valid_pred.round().astype(int), weights='quadratic')\n",
        "\n",
        "print(f\"Validation RMSE: {valid_rmse}\")\n",
        "print(f\"Validation Quadratic Weighted Kappa: {valid_kappa}\")\n",
        "\n",
        "# Save the model to a file\n",
        "model_save_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/XGBR-Model.h5'\n",
        "joblib.dump(best_xgb_model, model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bs-HxpVsa2ig",
        "outputId": "74f88a6a-b2cb-45f0-e398-3b3feb7da314"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission saved to /content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/submission_xgbrfeturd.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import joblib\n",
        "from lightgbm import LGBMRegressor  # Import LightGBM\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load test data\n",
        "test_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/test.csv'\n",
        "df_test = pd.read_csv(test_path)\n",
        "\n",
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    preprocessed_text = ' '.join(filtered_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Apply preprocessing to 'full_text' column in test data\n",
        "df_test['clean_text'] = df_test['full_text'].apply(preprocess_text)\n",
        "\n",
        "# Load TF-IDF vectorizer\n",
        "vectorizer_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/xgbrtfidf_vectorizer.joblib'\n",
        "tfidf_vectorizer = joblib.load(vectorizer_path)\n",
        "\n",
        "# Transform test data using TF-IDF vectorizer\n",
        "X_tfidf_test = tfidf_vectorizer.transform(df_test['clean_text'])\n",
        "\n",
        "# Additional features for test data\n",
        "df_test['text_length'] = df_test['full_text'].apply(len)\n",
        "df_test['word_count'] = df_test['full_text'].apply(lambda x: len(x.split()))\n",
        "df_test['avg_word_length'] = df_test['full_text'].apply(lambda x: np.mean([len(word) for word in x.split()]))\n",
        "df_test['sentence_count'] = df_test['full_text'].apply(lambda x: len(re.split(r'[.!?]', x)))\n",
        "\n",
        "# Combine TF-IDF features with selected additional features\n",
        "X_test_features = np.hstack((X_tfidf_test.toarray(), df_test[['text_length', 'word_count', 'avg_word_length', 'sentence_count']].values))\n",
        "\n",
        "# Load the trained LightGBM model\n",
        "model_load_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/XGBR-Model.h5'\n",
        "lgbm_model = joblib.load(model_load_path)\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_pred = lgbm_model.predict(X_test_features)\n",
        "y_test_pred = np.round(y_test_pred).astype(int)  # Round predictions to nearest integer\n",
        "y_test_pred = np.clip(y_test_pred, 1, 6)  # Clip predictions to the range [1, 6]\n",
        "\n",
        "# Prepare submission DataFrame\n",
        "submission_df = pd.DataFrame({'essay_id': df_test['essay_id'], 'predicted_score': y_test_pred})\n",
        "\n",
        "# Save submission to CSV file\n",
        "submission_save_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/submission_xgbrfeturd.csv'\n",
        "submission_df.to_csv(submission_save_path, index=False)\n",
        "print(f\"Submission saved to {submission_save_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0IjPJM8ZZWi"
      },
      "source": [
        "**xgbr with some new faetures**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOdXaykzZYwR",
        "outputId": "f2b863f6-869f-4e91-a0d1-7d0586a16317"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission saved to /content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/xgbrlinearsubmissions.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import joblib\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Download NLTK resources (if not already downloaded)\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load test data\n",
        "test_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/test.csv'\n",
        "df_test = pd.read_csv(test_path)\n",
        "\n",
        "# Text preprocessing function (same as used for training data)\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    preprocessed_text = ' '.join(filtered_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Apply preprocessing to 'full_text' column in test data\n",
        "df_test['clean_text'] = df_test['full_text'].apply(preprocess_text)\n",
        "\n",
        "# Load the trained TF-IDF vectorizer\n",
        "vectorizer_load_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/xgbrlineartfidf_vectorizer.joblib'\n",
        "tfidf_vectorizer = joblib.load(vectorizer_load_path)\n",
        "\n",
        "# TF-IDF Vectorization on test data\n",
        "X_tfidf_test = tfidf_vectorizer.transform(df_test['clean_text'])\n",
        "\n",
        "# Additional features for test data\n",
        "df_test['text_length'] = df_test['full_text'].apply(len)\n",
        "df_test['word_count'] = df_test['full_text'].apply(lambda x: len(x.split()))\n",
        "df_test['avg_word_length'] = df_test['full_text'].apply(lambda x: np.mean([len(word) for word in x.split()]))\n",
        "df_test['sentiment'] = df_test['full_text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "\n",
        "# Combine TF-IDF features with additional features\n",
        "X_test = np.hstack((X_tfidf_test.toarray(), df_test[['text_length', 'word_count', 'avg_word_length', 'sentiment']].values))\n",
        "\n",
        "# Load the trained XGBoost model\n",
        "model_load_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/xgbrlinearModel.h5'\n",
        "best_ensemble_model = joblib.load(model_load_path)\n",
        "\n",
        "# Predict on the test set\n",
        "y_test_pred = best_ensemble_model.predict(X_test)\n",
        "y_test_pred_rounded = np.round(y_test_pred).astype(int)  # Round predictions to nearest integer\n",
        "y_test_pred_clipped = np.clip(y_test_pred_rounded, 1, 6)  # Clip predictions to the range [1, 6]\n",
        "\n",
        "# Prepare submission DataFrame\n",
        "submission_df = pd.DataFrame({'essay_id': df_test['essay_id'], 'predicted_score': y_test_pred_clipped})\n",
        "\n",
        "# Save submission to CSV file\n",
        "submission_save_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/xgbrlinearsubmissions.csv'\n",
        "submission_df.to_csv(submission_save_path, index=False)\n",
        "print(f\"Submission saved to {submission_save_path}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFDFkXdLz_dg"
      },
      "source": [
        "#**M2 imporved xgbr**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6t1JkwxfXhu",
        "outputId": "34262fdb-0044-496c-ee3b-fa950e5a7ab9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters: {'subsample': 1.0, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
            "Validation RMSE: 0.5980248191534405\n",
            "Validation Quadratic Weighted Kappa: 0.7799444202195857\n",
            "Model saved to /content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/EssayModel.h5\n",
            "TF-IDF Vectorizer saved to /content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/Essaytfidf_vectorizer.joblib\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import mean_squared_error, cohen_kappa_score\n",
        "import joblib\n",
        "from scipy.stats import kurtosis\n",
        "\n",
        "# Download NLTK resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Function to preprocess text\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    preprocessed_text = ' '.join(filtered_tokens)\n",
        "    return preprocessed_text\n",
        "\n",
        "# Function to remove HTML tags\n",
        "def removeHTML(x):\n",
        "    html = re.compile(r'<.*?>')\n",
        "    return html.sub(r'', x)\n",
        "\n",
        "# Function for comprehensive data preprocessing\n",
        "def dataPreprocessing(x):\n",
        "    x = x.lower()\n",
        "    x = removeHTML(x)\n",
        "    x = re.sub(\"@\\w+\", '', x)\n",
        "    x = re.sub(\"http\\w+\", '', x)\n",
        "    x = re.sub(r\"\\s+\", \" \", x)\n",
        "    x = re.sub(r\"\\.+\", \".\", x)\n",
        "    x = re.sub(r\"\\,+\", \",\", x)\n",
        "    x = x.strip()\n",
        "    return x\n",
        "\n",
        "# Function to remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    return re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "# Function to count spelling errors\n",
        "def count_spelling_errors(text):\n",
        "    # Implement your own logic or use a library like spaCy to count spelling errors\n",
        "    return 0  # Placeholder\n",
        "\n",
        "# Function to preprocess words\n",
        "def Word_Preprocess(tmp):\n",
        "    tmp['clean_text'] = tmp['full_text'].apply(dataPreprocessing)\n",
        "    words = tmp[['essay_id', 'clean_text']].copy()\n",
        "    words = words.assign(word=words['clean_text'].str.split()).explode('word').reset_index(drop=True)\n",
        "    words['word_len'] = words['word'].apply(len)\n",
        "    words = words[words['word_len'] > 0]  # Remove words with length 0\n",
        "    return words\n",
        "\n",
        "# Function for word feature engineering\n",
        "def Word_Eng(words):\n",
        "    word_aggs = {\n",
        "        'word_len': ['max', 'mean', 'std', lambda x: x.quantile(0.25), lambda x: x.quantile(0.50), lambda x: x.quantile(0.75)]\n",
        "    }\n",
        "    essay_features = words.groupby('essay_id').agg(word_aggs)\n",
        "    essay_features.columns = ['_'.join(col).strip() for col in essay_features.columns.values]\n",
        "    return essay_features.reset_index()\n",
        "\n",
        "# Function to preprocess sentences\n",
        "def Sentence_Preprocess(tmp):\n",
        "    tmp['clean_text'] = tmp['full_text'].apply(dataPreprocessing)\n",
        "    sentences = tmp[['essay_id', 'clean_text']].copy()\n",
        "    sentences = sentences.assign(sentence=sentences['clean_text'].str.split('.')).explode('sentence').reset_index(drop=True)\n",
        "    sentences['sentence_len'] = sentences['sentence'].apply(len)\n",
        "    sentences['sentence_word_cnt'] = sentences['sentence'].apply(lambda x: len(x.split()))\n",
        "    sentences = sentences[sentences['sentence_len'] >= 15]  # Filter sentences with length >= 15\n",
        "    return sentences\n",
        "\n",
        "# Function for sentence feature engineering\n",
        "def Sentence_Eng(sentences):\n",
        "    sentence_aggs = {\n",
        "        'sentence_len': ['count', 'max', 'mean', 'min', 'sum', 'first', 'last', kurtosis, lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)],\n",
        "        'sentence_word_cnt': ['max', 'mean', 'min', 'sum', 'first', 'last', kurtosis, lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)]\n",
        "    }\n",
        "    essay_features = sentences.groupby('essay_id').agg(sentence_aggs)\n",
        "    essay_features.columns = ['_'.join(col).strip() for col in essay_features.columns.values]\n",
        "    return essay_features.reset_index()\n",
        "\n",
        "# Function to preprocess paragraphs\n",
        "def Paragraph_Preprocess(tmp):\n",
        "    tmp = tmp.explode('paragraph')\n",
        "    tmp['clean_paragraph'] = tmp['paragraph'].apply(dataPreprocessing)\n",
        "    tmp['paragraph_no_punctuation'] = tmp['clean_paragraph'].apply(remove_punctuation)\n",
        "    tmp['paragraph_error_num'] = tmp['paragraph_no_punctuation'].apply(count_spelling_errors)\n",
        "    tmp['paragraph_len'] = tmp['paragraph'].apply(len)\n",
        "    tmp['paragraph_sentence_cnt'] = tmp['paragraph'].apply(lambda x: len(re.split(r'\\.|!|\\?', x)))\n",
        "    tmp['paragraph_word_cnt'] = tmp['paragraph'].apply(lambda x: len(x.split()))\n",
        "    return tmp\n",
        "\n",
        "# Function for paragraph feature engineering\n",
        "def Paragraph_Eng(paragraphs):\n",
        "    paragraph_aggs = {\n",
        "        'paragraph_len': ['max', 'mean', 'std', lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)],\n",
        "        'paragraph_sentence_cnt': ['max', 'mean', 'std', lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)],\n",
        "        'paragraph_word_cnt': ['max', 'mean', 'std', lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)],\n",
        "        'paragraph_error_num': ['max', 'mean', 'std', lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)]\n",
        "    }\n",
        "    essay_features = paragraphs.groupby('essay_id').agg(paragraph_aggs)\n",
        "    essay_features.columns = ['_'.join(col).strip() for col in essay_features.columns.values]\n",
        "    return essay_features.reset_index()\n",
        "\n",
        "# Load training data\n",
        "train_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/train.csv'\n",
        "df_train = pd.read_csv(train_path)\n",
        "\n",
        "# Apply preprocessing to 'full_text' column\n",
        "df_train['clean_text'] = df_train['full_text'].apply(preprocess_text)\n",
        "\n",
        "# Additional textual features\n",
        "df_train['num_chars'] = df_train['full_text'].apply(len)\n",
        "df_train['num_words'] = df_train['full_text'].apply(lambda x: len(x.split()))\n",
        "df_train['num_sentences'] = df_train['full_text'].apply(lambda x: len(sent_tokenize(x)))\n",
        "df_train['AvgWordLength'] = df_train['num_chars'] / df_train['num_words']\n",
        "\n",
        "# Word features\n",
        "words_df = Word_Preprocess(df_train)\n",
        "word_features = Word_Eng(words_df)\n",
        "df_train = df_train.merge(word_features, on='essay_id', how='left')\n",
        "\n",
        "# Sentence features\n",
        "sentences_df = Sentence_Preprocess(df_train)\n",
        "sentence_features = Sentence_Eng(sentences_df)\n",
        "df_train = df_train.merge(sentence_features, on='essay_id', how='left')\n",
        "\n",
        "# Paragraph features\n",
        "df_train['paragraph'] = df_train['full_text'].str.split('\\n')\n",
        "paragraphs_df = Paragraph_Preprocess(df_train)\n",
        "paragraph_features = Paragraph_Eng(paragraphs_df)\n",
        "df_train = df_train.merge(paragraph_features, on='essay_id', how='left')\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df_train['clean_text'])\n",
        "\n",
        "# Combine TF-IDF features with additional features\n",
        "X = np.hstack((X_tfidf.toarray(), df_train[['num_chars', 'num_words', 'num_sentences', 'AvgWordLength']].values))\n",
        "y = df_train['score']\n",
        "\n",
        "# Split data into training and validation sets\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the parameter grid for RandomizedSearchCV\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'subsample': [0.6, 0.8, 1.0],\n",
        "    'colsample_bytree': [0.6, 0.8, 1.0]\n",
        "}\n",
        "\n",
        "# Initialize the model\n",
        "xgb_model = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# Setup the random search with 5-fold cross-validation\n",
        "random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_grid, n_iter=50, scoring='neg_mean_squared_error', cv=5, verbose=1, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Fit the random search model\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = random_search.best_params_\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "# Train the model with the best parameters\n",
        "best_xgb_model = XGBRegressor(**best_params)\n",
        "best_xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_valid_pred = best_xgb_model.predict(X_valid)\n",
        "y_valid_pred = np.clip(y_valid_pred, 1, 6)  # Assuming scores range from 1 to 6\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "valid_rmse = np.sqrt(mean_squared_error(y_valid, y_valid_pred))\n",
        "valid_kappa = cohen_kappa_score(y_valid.round().astype(int), y_valid_pred.round().astype(int), weights='quadratic')\n",
        "\n",
        "print(f\"Validation RMSE: {valid_rmse}\")\n",
        "print(f\"Validation Quadratic Weighted Kappa: {valid_kappa}\")\n",
        "\n",
        "# Save the model to a file\n",
        "model_save_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/EssayModel.h5'\n",
        "joblib.dump(best_xgb_model, model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")\n",
        "\n",
        "# Save the TF-IDF vectorizer\n",
        "vectorizer_save_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/Essaytfidf_vectorizer.joblib'\n",
        "joblib.dump(tfidf_vectorizer, vectorizer_save_path)\n",
        "print(f\"TF-IDF Vectorizer saved to {vectorizer_save_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0HHb5xtWFCA"
      },
      "source": [
        "# **M6.deberta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-Q1XoV8WGFb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from gensim.models import Word2Vec\n",
        "from transformers import AutoTokenizer, DebertaForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from datasets import Dataset\n",
        "\n",
        "# Define path to your train.csv file\n",
        "train_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/train.csv'\n",
        "\n",
        "# Load data\n",
        "df_train = pd.read_csv(train_path)\n",
        "\n",
        "# Adjust labels to start from 0 (assuming score ranges from 1 to 6)\n",
        "df_train['labels'] = df_train['score'] - 1\n",
        "\n",
        "# Initialize and train Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences=df_train['full_text'].apply(str.split).tolist(), vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Function to embed text using Word2Vec model\n",
        "def embed_text(text):\n",
        "    embedded_text = []\n",
        "    for word in text.split():\n",
        "        if word in word2vec_model.wv:\n",
        "            embedded_text.append(word2vec_model.wv[word])\n",
        "        else:\n",
        "            embedded_text.append(np.zeros(word2vec_model.vector_size))  # Handle out-of-vocabulary words\n",
        "    return np.mean(embedded_text, axis=0)  # Average embeddings of words in the text\n",
        "\n",
        "# Tokenizer for the input text\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base')\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch['full_text'], padding=True, truncation=True)\n",
        "\n",
        "# Prepare datasets\n",
        "ds_train = Dataset.from_pandas(df_train)\n",
        "\n",
        "# Embedding datasets with Word2Vec embeddings\n",
        "ds_train = ds_train.map(lambda x: {'embeddings': embed_text(x['full_text'])}, batched=True)\n",
        "\n",
        "# Define training and validation sets\n",
        "train_dataset, val_dataset = train_test_split(ds_train, test_size=0.1, random_state=42)\n",
        "\n",
        "# Define training arguments\n",
        "train_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',\n",
        "    logging_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,\n",
        "    warmup_ratio=0.1,\n",
        "    lr_scheduler_type='linear',\n",
        "    gradient_accumulation_steps=4,\n",
        "    report_to='none',\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='eval_loss',\n",
        "    greater_is_better=False,\n",
        ")\n",
        "\n",
        "# Define model\n",
        "model = DebertaForSequenceClassification.from_pretrained('microsoft/deberta-v3-base', num_labels=6)\n",
        "\n",
        "# Define compute metrics function (for evaluation)\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = np.argmax(pred.predictions, axis=1)\n",
        "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
        "    return {'cohen_kappa': kappa}\n",
        "\n",
        "# Create Trainer instance\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=train_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer),\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/deberta-v3-trained-model')\n",
        "\n",
        "# Optionally, save tokenizer\n",
        "tokenizer.save_pretrained('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/deberta-v3-tokenizer')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sOYS3YSg7-z"
      },
      "source": [
        "#**M5. BERT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "4037dd70f2c74023bd07b20cd266637b",
            "9b14cad09d054dfeac29c6c9bf60f052",
            "011b8d45b122478e884fe2bc653d74f1",
            "1595064624d74e99bf0a23bc48e37371",
            "f40e7895e5a648d19ce338a302cd52bb",
            "a8a2e9386dae424babb10a49f657d348",
            "b63d94b831b64f29a0c8aa0055f3e2e3",
            "167f9adbcf4345ae949d37bd5d875f6a",
            "d5a6cacf1cb94ba794834e69115fab86",
            "ac0b8023318745bbb44dffdb4917cd40",
            "9fb75d490e67415d9e9fb7e2ee25aa39",
            "cfdef32ac42a4f4b9979ca9eb407b0f0",
            "452ebf0963c14b83b1f68350f1894abf",
            "ba30f46214f24d9abde5dfcce5d5b5fc",
            "803fa954a89a4add909b30e940134d6d",
            "bf0084c29e9b420b94560a85617a5955",
            "45892b5a1e554e3a8a43ae77d6c09f3f",
            "d6d2553d11944f5289d0ae9c496b7d46",
            "6d4432105c3e49b982552bc2b4b125c8",
            "ee3f78323bae40e58b8d35c461e50ed1",
            "f736c90796e04d5aa6cfb6e962616030",
            "004ebe7d55f545c6b074c1186369cc81",
            "bda1ffe2957f4a68bd6875c830cacde3",
            "16ff150a77394df1a4482f20b887be8c",
            "831c9bc175fd43dd9e2b1d7b50918933",
            "afe94eae80e145609100c29b4224161c",
            "3b776580c37144eeaccfd3ddafd4e456",
            "84181a6d4f904f99ba144f936cc85639",
            "a870d2c205204f1b9744a24d5f996a66",
            "6d0a3cb5d1d64b7591a6b294cacda4f2",
            "69674d8a70d74bda93f4879ee7463ec4",
            "51815149d71749e5acdad988eb9bfdcc",
            "1fc3d47a107e4411ad8af41b500960e7",
            "2af881dfc3c542269e48c6049be13240",
            "3dfe7c367b5241b98bbd66c30970aacd",
            "0e7c7998f1b14ce9bd32709b06f33a29",
            "e22cf89c47ad4f7fa67cf18a9e18e48b",
            "0a900f72159245d4bce667cb878ed0fb",
            "ae7f8765cdaa4566ba95a3540b586228",
            "c0c247ab383d4c358be54fb787bce62a",
            "cbbebd3d094848f5aac04848bd8f50d8",
            "d4ad4afb79384be6bea9627fc73abb63",
            "f03b958b44af42a7828a2178f587b324",
            "b99f7b1f5742403289ebba79a2e3a444"
          ]
        },
        "id": "SbfI3daghAzX",
        "outputId": "fc7d4d73-7b16-4d91-c347-e23ad06454d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4037dd70f2c74023bd07b20cd266637b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cfdef32ac42a4f4b9979ca9eb407b0f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bda1ffe2957f4a68bd6875c830cacde3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2af881dfc3c542269e48c6049be13240",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, cohen_kappa_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Assuming preprocess_text function is defined\n",
        "def preprocess_text(text):\n",
        "    # Add your text preprocessing steps here\n",
        "    return text\n",
        "\n",
        "class EssayDataset(Dataset):\n",
        "    def __init__(self, texts, scores, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.scores = scores\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        score = float(self.scores[idx])\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = inputs['input_ids'].squeeze(0)\n",
        "        attention_mask = inputs['attention_mask'].squeeze(0)\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'score': torch.tensor(score, dtype=torch.float)\n",
        "        }\n",
        "\n",
        "class CNNTextClassifier(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_filters, filter_sizes, output_dim, dropout):\n",
        "        super(CNNTextClassifier, self).__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(len(tokenizer), embedding_dim)\n",
        "        self.convs = nn.ModuleList([\n",
        "            nn.Conv2d(in_channels=1, out_channels=num_filters, kernel_size=(fs, embedding_dim))\n",
        "            for fs in filter_sizes\n",
        "        ])\n",
        "        self.fc = nn.Linear(num_filters * len(filter_sizes), output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        embedded = self.embedding(input_ids)\n",
        "        embedded = embedded.unsqueeze(1)  # add channel dimension (batch_size, channels, seq_len, embed_dim)\n",
        "\n",
        "        conved = [F.relu(conv(embedded)).squeeze(3) for conv in self.convs]  # convolution over embedding\n",
        "        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]  # max-pooling over time\n",
        "        cat = self.dropout(torch.cat(pooled, dim=1))  # concatenate pooled layers\n",
        "\n",
        "        return self.fc(cat)\n",
        "\n",
        "# Hyperparameters\n",
        "MAX_LEN = 512\n",
        "OUTPUT_DIM = 1\n",
        "BATCH_SIZE = 8\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load and preprocess data\n",
        "df = pd.read_csv('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/train.csv')\n",
        "df['clean_text'] = df['full_text'].apply(preprocess_text)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "df_train, df_val = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Data preparation\n",
        "train_dataset = EssayDataset(df_train['clean_text'].tolist(), df_train['score'].tolist(), tokenizer, MAX_LEN)\n",
        "val_dataset = EssayDataset(df_val['clean_text'].tolist(), df_val['score'].tolist(), tokenizer, MAX_LEN)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# Hyperparameter search space\n",
        "param_grid = {\n",
        "    'embedding_dim': [50, 100, 200],\n",
        "    'num_filters': [50, 100, 200],\n",
        "    'filter_sizes': [[2, 3, 4], [3, 4, 5], [4, 5, 6]],\n",
        "    'dropout': [0.3, 0.5, 0.7],\n",
        "    'learning_rate': [0.001, 0.0001, 0.00001]\n",
        "}\n",
        "\n",
        "best_rmse = float('inf')\n",
        "best_params = {}\n",
        "\n",
        "for embedding_dim in param_grid['embedding_dim']:\n",
        "    for num_filters in param_grid['num_filters']:\n",
        "        for filter_sizes in param_grid['filter_sizes']:\n",
        "            for dropout in param_grid['dropout']:\n",
        "                for learning_rate in param_grid['learning_rate']:\n",
        "                    # Model initialization\n",
        "                    model = CNNTextClassifier(embedding_dim, num_filters, filter_sizes, OUTPUT_DIM, dropout)\n",
        "                    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "                    criterion = nn.MSELoss()\n",
        "\n",
        "                    # Training loop\n",
        "                    model.train()\n",
        "                    for epoch in range(NUM_EPOCHS):\n",
        "                        epoch_loss = 0\n",
        "                        for batch in train_loader:\n",
        "                            input_ids = batch['input_ids']\n",
        "                            attention_mask = batch['attention_mask']\n",
        "                            scores = batch['score']\n",
        "\n",
        "                            optimizer.zero_grad()\n",
        "                            outputs = model(input_ids, attention_mask)\n",
        "                            loss = criterion(outputs.squeeze(1), scores)\n",
        "                            loss.backward()\n",
        "                            optimizer.step()\n",
        "\n",
        "                            epoch_loss += loss.item()\n",
        "\n",
        "                    # Evaluation\n",
        "                    model.eval()\n",
        "                    predictions = []\n",
        "                    true_labels = []\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        for batch in val_loader:\n",
        "                            input_ids = batch['input_ids']\n",
        "                            attention_mask = batch['attention_mask']\n",
        "                            scores = batch['score']\n",
        "\n",
        "                            outputs = model(input_ids, attention_mask)\n",
        "                            predictions.extend(outputs.squeeze(1).tolist())\n",
        "                            true_labels.extend(scores.tolist())\n",
        "\n",
        "                    predictions = np.array(predictions)\n",
        "                    true_labels = np.array(true_labels)\n",
        "\n",
        "                    # Compute evaluation metrics\n",
        "                    rmse = np.sqrt(mean_squared_error(true_labels, predictions))\n",
        "\n",
        "                    if rmse < best_rmse:\n",
        "                        best_rmse = rmse\n",
        "                        best_params = {\n",
        "                            'embedding_dim': embedding_dim,\n",
        "                            'num_filters': num_filters,\n",
        "                            'filter_sizes': filter_sizes,\n",
        "                            'dropout': dropout,\n",
        "                            'learning_rate': learning_rate\n",
        "                        }\n",
        "\n",
        "print(f\"Best RMSE: {best_rmse}\")\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "# Use the best hyperparameters to train the final model\n",
        "model = CNNTextClassifier(\n",
        "    best_params['embedding_dim'],\n",
        "    best_params['num_filters'],\n",
        "    best_params['filter_sizes'],\n",
        "    OUTPUT_DIM,\n",
        "    best_params['dropout']\n",
        ")\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=best_params['learning_rate'])\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Training loop with the best hyperparameters\n",
        "model.train()\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    epoch_loss = 0\n",
        "    for batch in train_loader:\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        scores = batch['score']\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        loss = criterion(outputs.squeeze(1), scores)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {epoch_loss / len(train_loader)}')\n",
        "\n",
        "# Evaluation with the best hyperparameters\n",
        "model.eval()\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        scores = batch['score']\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        predictions.extend(outputs.squeeze(1).tolist())\n",
        "        true_labels.extend(scores.tolist())\n",
        "\n",
        "predictions = np.array(predictions)\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "rmse = np.sqrt(mean_squared_error(true_labels, predictions))\n",
        "kappa = cohen_kappa_score(true_labels.round().astype(int), predictions.round().astype(int), weights='quadratic')\n",
        "accuracy = accuracy_score(true_labels.round().astype(int), predictions.round().astype(int))\n",
        "\n",
        "print(f\"RMSE: {rmse}\")\n",
        "print(f\"Quadratic Weighted Kappa (Kappa): {kappa}\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/nn_modelessay scoring.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlt8KuEO0zZa",
        "outputId": "27ff863e-db57-4cb8-ec8c-c916770fb655"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\rTraining:   0%|          | 0/217 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "Training: 100%|| 217/217 [02:38<00:00,  1.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50, Loss: 0.40466519493249153, Time: 158.07s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:54<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Evaluation Metrics:\n",
            "RMSE: 0.6982304021454449\n",
            "Quadratic Weighted Kappa (Kappa): 0.683642774053911\n",
            "Accuracy: 0.5571923743500866\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/50, Loss: 0.14446980355110037, Time: 163.05s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Evaluation Metrics:\n",
            "RMSE: 0.6700893663243178\n",
            "Quadratic Weighted Kappa (Kappa): 0.711170740937245\n",
            "Accuracy: 0.573367995378394\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/50, Loss: 0.12989238261627162, Time: 162.98s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Evaluation Metrics:\n",
            "RMSE: 0.6543974513993895\n",
            "Quadratic Weighted Kappa (Kappa): 0.7250903854941664\n",
            "Accuracy: 0.586366262276141\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/50, Loss: 0.11936697525225477, Time: 163.22s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:54<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Evaluation Metrics:\n",
            "RMSE: 0.6380247536515399\n",
            "Quadratic Weighted Kappa (Kappa): 0.735267616085123\n",
            "Accuracy: 0.598209127671866\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/50, Loss: 0.11246090021825605, Time: 162.86s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Evaluation Metrics:\n",
            "RMSE: 0.6234925828594748\n",
            "Quadratic Weighted Kappa (Kappa): 0.7577175762748476\n",
            "Accuracy: 0.6068746389370306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/50, Loss: 0.1051588274607186, Time: 163.06s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Evaluation Metrics:\n",
            "RMSE: 0.6496980620354943\n",
            "Quadratic Weighted Kappa (Kappa): 0.7348904049447964\n",
            "Accuracy: 0.5800115540150202\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/50, Loss: 0.10028505950204787, Time: 163.06s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Evaluation Metrics:\n",
            "RMSE: 0.6323654850030791\n",
            "Quadratic Weighted Kappa (Kappa): 0.7501177902087248\n",
            "Accuracy: 0.5967648757943386\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/50, Loss: 0.0962517044511259, Time: 163.13s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Evaluation Metrics:\n",
            "RMSE: 0.6068556035454015\n",
            "Quadratic Weighted Kappa (Kappa): 0.7682607888831121\n",
            "Accuracy: 0.6181398035817447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/50, Loss: 0.09244598367590509, Time: 163.37s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Evaluation Metrics:\n",
            "RMSE: 0.604166363889502\n",
            "Quadratic Weighted Kappa (Kappa): 0.7700299525086801\n",
            "Accuracy: 0.6158290005777007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/50, Loss: 0.0893331060040107, Time: 163.18s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Evaluation Metrics:\n",
            "RMSE: 0.6187785542543157\n",
            "Quadratic Weighted Kappa (Kappa): 0.7583320745389379\n",
            "Accuracy: 0.6048526863084922\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/50, Loss: 0.0841705818845105, Time: 163.19s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 Evaluation Metrics:\n",
            "RMSE: 0.6128776969290137\n",
            "Quadratic Weighted Kappa (Kappa): 0.7710536838245909\n",
            "Accuracy: 0.610051993067591\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/50, Loss: 0.08245461003228266, Time: 162.92s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 Evaluation Metrics:\n",
            "RMSE: 0.6000161538235298\n",
            "Quadratic Weighted Kappa (Kappa): 0.776904550243817\n",
            "Accuracy: 0.6187175043327556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13/50, Loss: 0.07934273643771075, Time: 162.46s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:54<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 Evaluation Metrics:\n",
            "RMSE: 0.5947474557922549\n",
            "Quadratic Weighted Kappa (Kappa): 0.7810828242971506\n",
            "Accuracy: 0.6221837088388215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14/50, Loss: 0.07647375904950678, Time: 162.99s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:54<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 Evaluation Metrics:\n",
            "RMSE: 0.5931219523497732\n",
            "Quadratic Weighted Kappa (Kappa): 0.7811833584855672\n",
            "Accuracy: 0.6227614095898325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15/50, Loss: 0.0740631176716721, Time: 162.62s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 Evaluation Metrics:\n",
            "RMSE: 0.6087962849038289\n",
            "Quadratic Weighted Kappa (Kappa): 0.7784082010700866\n",
            "Accuracy: 0.6155401502021952\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16/50, Loss: 0.07149689124407856, Time: 162.80s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 Evaluation Metrics:\n",
            "RMSE: 0.6043809942770745\n",
            "Quadratic Weighted Kappa (Kappa): 0.7831444084623412\n",
            "Accuracy: 0.6158290005777007\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17/50, Loss: 0.06986331666738207, Time: 162.94s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 Evaluation Metrics:\n",
            "RMSE: 0.5947845569945884\n",
            "Quadratic Weighted Kappa (Kappa): 0.7785947967858655\n",
            "Accuracy: 0.6184286539572501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18/50, Loss: 0.06781268162730103, Time: 163.00s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 Evaluation Metrics:\n",
            "RMSE: 0.6058876224944968\n",
            "Quadratic Weighted Kappa (Kappa): 0.7794643151836489\n",
            "Accuracy: 0.6109185441941074\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19/50, Loss: 0.06514481946070623, Time: 162.86s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:54<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 Evaluation Metrics:\n",
            "RMSE: 0.5878197298594431\n",
            "Quadratic Weighted Kappa (Kappa): 0.7857792876573605\n",
            "Accuracy: 0.6268053148469093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20/50, Loss: 0.06297679044615288, Time: 162.81s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 Evaluation Metrics:\n",
            "RMSE: 0.5947306887899573\n",
            "Quadratic Weighted Kappa (Kappa): 0.786367610131921\n",
            "Accuracy: 0.6256499133448874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21/50, Loss: 0.05950486397344945, Time: 163.08s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 Evaluation Metrics:\n",
            "RMSE: 0.5884716044349673\n",
            "Quadratic Weighted Kappa (Kappa): 0.786143376781466\n",
            "Accuracy: 0.6262276140958983\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22/50, Loss: 0.05805432950983399, Time: 163.03s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 Evaluation Metrics:\n",
            "RMSE: 0.6006585285303189\n",
            "Quadratic Weighted Kappa (Kappa): 0.7827680389433856\n",
            "Accuracy: 0.6195840554592721\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23/50, Loss: 0.055455782515112705, Time: 162.89s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 Evaluation Metrics:\n",
            "RMSE: 0.591094422609862\n",
            "Quadratic Weighted Kappa (Kappa): 0.7868545113395581\n",
            "Accuracy: 0.6247833622183708\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24/50, Loss: 0.053682710348804424, Time: 162.96s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 Evaluation Metrics:\n",
            "RMSE: 0.5894162097835776\n",
            "Quadratic Weighted Kappa (Kappa): 0.7858214426362335\n",
            "Accuracy: 0.6221837088388215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25/50, Loss: 0.05107465025878722, Time: 163.23s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 Evaluation Metrics:\n",
            "RMSE: 0.5970759877002011\n",
            "Quadratic Weighted Kappa (Kappa): 0.7826266179962327\n",
            "Accuracy: 0.6155401502021952\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26/50, Loss: 0.04898167159494167, Time: 162.94s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:54<00:00,  2.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 Evaluation Metrics:\n",
            "RMSE: 0.6059372309227361\n",
            "Quadratic Weighted Kappa (Kappa): 0.7827852630146525\n",
            "Accuracy: 0.6057192374350087\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27/50, Loss: 0.04794646787547296, Time: 163.13s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 Evaluation Metrics:\n",
            "RMSE: 0.5839748588627945\n",
            "Quadratic Weighted Kappa (Kappa): 0.7913379953801436\n",
            "Accuracy: 0.6250722125938764\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28/50, Loss: 0.04654449667386745, Time: 162.73s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 Evaluation Metrics:\n",
            "RMSE: 0.5843507552837202\n",
            "Quadratic Weighted Kappa (Kappa): 0.7915676140363579\n",
            "Accuracy: 0.6253610629693819\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29/50, Loss: 0.043664217089659056, Time: 162.77s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 Evaluation Metrics:\n",
            "RMSE: 0.5944782184040316\n",
            "Quadratic Weighted Kappa (Kappa): 0.7878832647708506\n",
            "Accuracy: 0.6164067013287118\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30/50, Loss: 0.042597350024957265, Time: 162.83s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 Evaluation Metrics:\n",
            "RMSE: 0.5954809749386819\n",
            "Quadratic Weighted Kappa (Kappa): 0.7835937344540795\n",
            "Accuracy: 0.6166955517042172\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31/50, Loss: 0.040002654654227095, Time: 163.04s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31 Evaluation Metrics:\n",
            "RMSE: 0.5896727331700989\n",
            "Quadratic Weighted Kappa (Kappa): 0.7856804429686031\n",
            "Accuracy: 0.6207394569612941\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32/50, Loss: 0.03985408007720923, Time: 163.10s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32 Evaluation Metrics:\n",
            "RMSE: 0.5932945346539906\n",
            "Quadratic Weighted Kappa (Kappa): 0.7857996068151032\n",
            "Accuracy: 0.6230502599653379\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33/50, Loss: 0.037855193104749454, Time: 163.14s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33 Evaluation Metrics:\n",
            "RMSE: 0.590473550496099\n",
            "Quadratic Weighted Kappa (Kappa): 0.7866484571415302\n",
            "Accuracy: 0.620161756210283\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34/50, Loss: 0.03632800993488131, Time: 163.09s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34 Evaluation Metrics:\n",
            "RMSE: 0.5872811623103357\n",
            "Quadratic Weighted Kappa (Kappa): 0.7925053363027519\n",
            "Accuracy: 0.6244945118428654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35/50, Loss: 0.03573647679649465, Time: 163.17s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35 Evaluation Metrics:\n",
            "RMSE: 0.5855129772310054\n",
            "Quadratic Weighted Kappa (Kappa): 0.7898449922029349\n",
            "Accuracy: 0.6268053148469093\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36/50, Loss: 0.03290832168014918, Time: 162.80s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36 Evaluation Metrics:\n",
            "RMSE: 0.5890770486395992\n",
            "Quadratic Weighted Kappa (Kappa): 0.7837095579917316\n",
            "Accuracy: 0.6216060080878105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37/50, Loss: 0.030906387317221836, Time: 162.79s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37 Evaluation Metrics:\n",
            "RMSE: 0.59045817689204\n",
            "Quadratic Weighted Kappa (Kappa): 0.7913121604909633\n",
            "Accuracy: 0.6239168110918544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38/50, Loss: 0.02979991482871194, Time: 163.13s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38 Evaluation Metrics:\n",
            "RMSE: 0.5929167723142729\n",
            "Quadratic Weighted Kappa (Kappa): 0.7807386087028183\n",
            "Accuracy: 0.6181398035817447\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39/50, Loss: 0.028689542493443885, Time: 162.76s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39 Evaluation Metrics:\n",
            "RMSE: 0.587127788840884\n",
            "Quadratic Weighted Kappa (Kappa): 0.7928674314024277\n",
            "Accuracy: 0.6233391103408434\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40/50, Loss: 0.027926107799883262, Time: 162.96s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:54<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 Evaluation Metrics:\n",
            "RMSE: 0.5914976557664432\n",
            "Quadratic Weighted Kappa (Kappa): 0.7865672061244037\n",
            "Accuracy: 0.6216060080878105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41/50, Loss: 0.027214253836307108, Time: 162.60s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41 Evaluation Metrics:\n",
            "RMSE: 0.5993766356155292\n",
            "Quadratic Weighted Kappa (Kappa): 0.7790027585329302\n",
            "Accuracy: 0.6120739456961294\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42/50, Loss: 0.026011388328286908, Time: 162.72s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42 Evaluation Metrics:\n",
            "RMSE: 0.6045595381208777\n",
            "Quadratic Weighted Kappa (Kappa): 0.7809897971875439\n",
            "Accuracy: 0.6068746389370306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43/50, Loss: 0.02521667268110036, Time: 162.88s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43 Evaluation Metrics:\n",
            "RMSE: 0.5912050556431989\n",
            "Quadratic Weighted Kappa (Kappa): 0.7832420190646792\n",
            "Accuracy: 0.6195840554592721\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44/50, Loss: 0.025144272844397252, Time: 162.90s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:54<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44 Evaluation Metrics:\n",
            "RMSE: 0.5933385804563528\n",
            "Quadratic Weighted Kappa (Kappa): 0.7877960925384917\n",
            "Accuracy: 0.6216060080878105\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45/50, Loss: 0.023171107829784467, Time: 162.75s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45 Evaluation Metrics:\n",
            "RMSE: 0.5910429792617983\n",
            "Quadratic Weighted Kappa (Kappa): 0.7907945309085935\n",
            "Accuracy: 0.623627960716349\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46/50, Loss: 0.023439569484596978, Time: 162.50s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:54<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46 Evaluation Metrics:\n",
            "RMSE: 0.5918555627015376\n",
            "Quadratic Weighted Kappa (Kappa): 0.785445323379506\n",
            "Accuracy: 0.6184286539572501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:43<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47/50, Loss: 0.02317319854596106, Time: 163.08s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47 Evaluation Metrics:\n",
            "RMSE: 0.6129386804910832\n",
            "Quadratic Weighted Kappa (Kappa): 0.7741461982581466\n",
            "Accuracy: 0.6019641825534373\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48/50, Loss: 0.023164475963275005, Time: 162.75s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48 Evaluation Metrics:\n",
            "RMSE: 0.598099071287511\n",
            "Quadratic Weighted Kappa (Kappa): 0.782645497563472\n",
            "Accuracy: 0.6138070479491623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49/50, Loss: 0.021617430682864883, Time: 162.60s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:54<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49 Evaluation Metrics:\n",
            "RMSE: 0.5918524028407814\n",
            "Quadratic Weighted Kappa (Kappa): 0.7833419175582119\n",
            "Accuracy: 0.6184286539572501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|| 217/217 [02:42<00:00,  1.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50/50, Loss: 0.020905970376894772, Time: 162.63s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 55/55 [01:55<00:00,  2.10s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50 Evaluation Metrics:\n",
            "RMSE: 0.5925820707674486\n",
            "Quadratic Weighted Kappa (Kappa): 0.7806214001917092\n",
            "Accuracy: 0.6138070479491623\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, cohen_kappa_score, accuracy_score\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "import tqdm\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "# Load training data\n",
        "train_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/train.csv'\n",
        "df_train = pd.read_csv(train_path)\n",
        "\n",
        "# Train-test split\n",
        "train_texts, val_texts, train_scores, val_scores = train_test_split(df_train['full_text'].tolist(), df_train['score'].tolist(), test_size=0.2, random_state=42)\n",
        "\n",
        "class EssayDataset(Dataset):\n",
        "    def __init__(self, texts, scores, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.scores = scores\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        score = float(self.scores[idx])\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = inputs['input_ids'].squeeze(0)\n",
        "        attention_mask = inputs['attention_mask'].squeeze(0)\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'score': torch.tensor(score, dtype=torch.float)\n",
        "        }\n",
        "\n",
        "class TextToImageCNN(nn.Module):\n",
        "    def __init__(self, bert_model, embedding_dim, num_filters, filter_sizes, output_dim, dropout):\n",
        "        super(TextToImageCNN, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.conv_layers = nn.ModuleList([\n",
        "            nn.Conv2d(1, num_filters, (fs, embedding_dim)) for fs in filter_sizes\n",
        "        ])\n",
        "        self.fc = nn.Linear(num_filters * len(filter_sizes), output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        with torch.no_grad():\n",
        "            bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # Convert BERT embeddings to a 2D image-like representation\n",
        "        embedded = bert_output.last_hidden_state.unsqueeze(1)  # (batch_size, 1, seq_len, embedding_dim)\n",
        "\n",
        "        conv_results = [F.relu(conv(embedded)).squeeze(3) for conv in self.conv_layers]\n",
        "        pooled_results = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conv_results]\n",
        "        concatenated = self.dropout(torch.cat(pooled_results, dim=1))\n",
        "\n",
        "        return self.fc(concatenated)\n",
        "\n",
        "# Hyperparameters\n",
        "MAX_LEN = 512\n",
        "EMBEDDING_DIM = 768  # BERT embedding size\n",
        "NUM_FILTERS = 256\n",
        "FILTER_SIZES = [3, 5, 7]\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0.4\n",
        "LEARNING_RATE = 0.0001\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 50\n",
        "GRADIENT_ACCUMULATION_STEPS = 4\n",
        "\n",
        "# Tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Data preparation\n",
        "train_dataset = EssayDataset(train_texts, train_scores, tokenizer, MAX_LEN)\n",
        "val_dataset = EssayDataset(val_texts, val_scores, tokenizer, MAX_LEN)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Model initialization\n",
        "model = TextToImageCNN(bert_model, EMBEDDING_DIM, NUM_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Optimizer and loss function\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Mixed precision training\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    start_time = time.time()\n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    for step, batch in enumerate(tqdm.tqdm(train_loader, desc=\"Training\")):\n",
        "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
        "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
        "        scores = batch['score'].to(device, non_blocking=True)\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            loss = criterion(outputs.squeeze(1), scores) / GRADIENT_ACCUMULATION_STEPS\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    avg_loss = epoch_loss / len(train_loader)\n",
        "    print(f'Epoch {epoch+1}/{NUM_EPOCHS}, Loss: {avg_loss}, Time: {time.time() - start_time:.2f}s')\n",
        "\n",
        "    # Evaluation after each epoch\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm.tqdm(val_loader, desc=\"Evaluating\"):\n",
        "            input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
        "            attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
        "            scores = batch['score'].to(device, non_blocking=True)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask)\n",
        "            predictions.extend(outputs.squeeze(1).tolist())\n",
        "            true_labels.extend(scores.tolist())\n",
        "\n",
        "    predictions = np.array(predictions)\n",
        "    true_labels = np.array(true_labels)\n",
        "\n",
        "    # Compute evaluation metrics\n",
        "    rmse = np.sqrt(mean_squared_error(true_labels, predictions))\n",
        "    kappa = cohen_kappa_score(true_labels.round().astype(int), predictions.round().astype(int), weights='quadratic')\n",
        "    accuracy = accuracy_score(true_labels.round().astype(int), predictions.round().astype(int))\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Evaluation Metrics:\")\n",
        "    print(f\"RMSE: {rmse}\")\n",
        "    print(f\"Quadratic Weighted Kappa (Kappa): {kappa}\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Save model\n",
        "torch.save(model.state_dict(), '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/cnnlstms_models.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR3xvGx6ZW6V",
        "outputId": "9f700f86-5073-448e-c607-16fa88f93fb8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Predicting: 100%|| 1/1 [00:02<00:00,  2.52s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission file saved to: /content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/submissionlstmcnn.csv\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tqdm\n",
        "\n",
        "# Define the EssayDataset class\n",
        "class EssayDataset(Dataset):\n",
        "    def __init__(self, texts, scores, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.scores = scores\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        score = float(self.scores[idx])\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids = inputs['input_ids'].squeeze(0)\n",
        "        attention_mask = inputs['attention_mask'].squeeze(0)\n",
        "\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'score': torch.tensor(score, dtype=torch.float)\n",
        "        }\n",
        "\n",
        "# Define the TextToImageCNN model class\n",
        "class TextToImageCNN(nn.Module):\n",
        "    def __init__(self, bert_model, embedding_dim, num_filters, filter_sizes, output_dim, dropout):\n",
        "        super(TextToImageCNN, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        self.conv_layers = nn.ModuleList([\n",
        "            nn.Conv2d(1, num_filters, (fs, embedding_dim)) for fs in filter_sizes\n",
        "        ])\n",
        "        self.fc = nn.Linear(num_filters * len(filter_sizes), output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        with torch.no_grad():\n",
        "            bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # Convert BERT embeddings to a 2D image-like representation\n",
        "        embedded = bert_output.last_hidden_state.unsqueeze(1)  # (batch_size, 1, seq_len, embedding_dim)\n",
        "\n",
        "        conv_results = [F.relu(conv(embedded)).squeeze(3) for conv in self.conv_layers]\n",
        "        pooled_results = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conv_results]\n",
        "        concatenated = self.dropout(torch.cat(pooled_results, dim=1))\n",
        "\n",
        "        return self.fc(concatenated)\n",
        "\n",
        "# Parameters\n",
        "MAX_LEN = 512\n",
        "EMBEDDING_DIM = 768  # BERT embedding size\n",
        "NUM_FILTERS = 256\n",
        "FILTER_SIZES = [3, 5, 7]\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0.4\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Load the tokenizer and BERT model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Initialize the model\n",
        "model = TextToImageCNN(bert_model, EMBEDDING_DIM, NUM_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the saved model weights with map_location\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/cnnlstms_models.pt', map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# Load test data\n",
        "test_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/test.csv'\n",
        "df_test = pd.read_csv(test_path)\n",
        "test_texts = df_test['full_text'].tolist()\n",
        "test_ids = df_test['essay_id'].tolist()\n",
        "\n",
        "# Prepare test dataset and loader\n",
        "test_dataset = EssayDataset(test_texts, [0]*len(test_texts), tokenizer, MAX_LEN)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Predictions\n",
        "predictions = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm.tqdm(test_loader, desc=\"Predicting\"):\n",
        "        input_ids = batch['input_ids'].to(device, non_blocking=True)\n",
        "        attention_mask = batch['attention_mask'].to(device, non_blocking=True)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask)\n",
        "        predictions.extend(outputs.squeeze(1).tolist())\n",
        "\n",
        "# Convert predictions to the required integer range (1-6)\n",
        "predictions = np.round(predictions).astype(int)\n",
        "predictions = np.clip(predictions, 1, 6)\n",
        "\n",
        "# Create submission dataframe\n",
        "submission = pd.DataFrame({'essay_id': test_ids, 'score': predictions})\n",
        "\n",
        "# Save submission file\n",
        "submission_path = '/content/drive/MyDrive/kaggleC/learning-agency-lab-automated-essay-scoring-2/submissionlstmcnn.csv'\n",
        "submission.to_csv(submission_path, index=False)\n",
        "\n",
        "print(\"Submission file saved to:\", submission_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "data = {\n",
        "    \"Index\": [1, 2, 3, 4, 5],\n",
        "    \"Model\": [\"Linear Regression\",\"XGBoost Regressor\",\n",
        "              \"BERT\", \"LSTM\", \"LightGBM (LGBM)\"],\n",
        "    \"Cohen's Kappa\": [0.654, 0.710,0.7806, 0.771, 0.721]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Print table\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "# Define colors (Red for NN and BERT)\n",
        "colors = [\"#1E3A5F\", \"#104E8B\", \"#0B3D91\", \"#166534\", \"#004D00\", \"#002400\"]\n",
        "# Light blue, sky blue, steel blue, light green, lime green, green\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.barh(df[\"Model\"], df[\"Cohen's Kappa\"], color=colors)\n",
        "plt.xlabel(\"Cohen's Kappa Score\")\n",
        "plt.ylabel(\"Model\")\n",
        "plt.title(\"Model Performance Comparison\")\n",
        "plt.gca().invert_yaxis()  # Invert y-axis for better readability\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "wDUZcXq5BSwd",
        "outputId": "c0a3c0a6-6287-4f82-98b4-da4c864a7774"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Index             Model  Cohen's Kappa\n",
            "     1 Linear Regression         0.6540\n",
            "     2 XGBoost Regressor         0.7100\n",
            "     3              BERT         0.7806\n",
            "     4              LSTM         0.7710\n",
            "     5   LightGBM (LGBM)         0.7210\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "004ebe7d55f545c6b074c1186369cc81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "011b8d45b122478e884fe2bc653d74f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_167f9adbcf4345ae949d37bd5d875f6a",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d5a6cacf1cb94ba794834e69115fab86",
            "value": 48
          }
        },
        "0a900f72159245d4bce667cb878ed0fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e7c7998f1b14ce9bd32709b06f33a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cbbebd3d094848f5aac04848bd8f50d8",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d4ad4afb79384be6bea9627fc73abb63",
            "value": 570
          }
        },
        "1595064624d74e99bf0a23bc48e37371": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac0b8023318745bbb44dffdb4917cd40",
            "placeholder": "",
            "style": "IPY_MODEL_9fb75d490e67415d9e9fb7e2ee25aa39",
            "value": "48.0/48.0[00:00&lt;00:00,3.87kB/s]"
          }
        },
        "167f9adbcf4345ae949d37bd5d875f6a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16ff150a77394df1a4482f20b887be8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84181a6d4f904f99ba144f936cc85639",
            "placeholder": "",
            "style": "IPY_MODEL_a870d2c205204f1b9744a24d5f996a66",
            "value": "tokenizer.json:100%"
          }
        },
        "1fc3d47a107e4411ad8af41b500960e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2af881dfc3c542269e48c6049be13240": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3dfe7c367b5241b98bbd66c30970aacd",
              "IPY_MODEL_0e7c7998f1b14ce9bd32709b06f33a29",
              "IPY_MODEL_e22cf89c47ad4f7fa67cf18a9e18e48b"
            ],
            "layout": "IPY_MODEL_0a900f72159245d4bce667cb878ed0fb"
          }
        },
        "3b776580c37144eeaccfd3ddafd4e456": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dfe7c367b5241b98bbd66c30970aacd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae7f8765cdaa4566ba95a3540b586228",
            "placeholder": "",
            "style": "IPY_MODEL_c0c247ab383d4c358be54fb787bce62a",
            "value": "config.json:100%"
          }
        },
        "4037dd70f2c74023bd07b20cd266637b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b14cad09d054dfeac29c6c9bf60f052",
              "IPY_MODEL_011b8d45b122478e884fe2bc653d74f1",
              "IPY_MODEL_1595064624d74e99bf0a23bc48e37371"
            ],
            "layout": "IPY_MODEL_f40e7895e5a648d19ce338a302cd52bb"
          }
        },
        "452ebf0963c14b83b1f68350f1894abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45892b5a1e554e3a8a43ae77d6c09f3f",
            "placeholder": "",
            "style": "IPY_MODEL_d6d2553d11944f5289d0ae9c496b7d46",
            "value": "vocab.txt:100%"
          }
        },
        "45892b5a1e554e3a8a43ae77d6c09f3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51815149d71749e5acdad988eb9bfdcc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69674d8a70d74bda93f4879ee7463ec4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d0a3cb5d1d64b7591a6b294cacda4f2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d4432105c3e49b982552bc2b4b125c8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "803fa954a89a4add909b30e940134d6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f736c90796e04d5aa6cfb6e962616030",
            "placeholder": "",
            "style": "IPY_MODEL_004ebe7d55f545c6b074c1186369cc81",
            "value": "232k/232k[00:00&lt;00:00,1.14MB/s]"
          }
        },
        "831c9bc175fd43dd9e2b1d7b50918933": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d0a3cb5d1d64b7591a6b294cacda4f2",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69674d8a70d74bda93f4879ee7463ec4",
            "value": 466062
          }
        },
        "84181a6d4f904f99ba144f936cc85639": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b14cad09d054dfeac29c6c9bf60f052": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a8a2e9386dae424babb10a49f657d348",
            "placeholder": "",
            "style": "IPY_MODEL_b63d94b831b64f29a0c8aa0055f3e2e3",
            "value": "tokenizer_config.json:100%"
          }
        },
        "9fb75d490e67415d9e9fb7e2ee25aa39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a870d2c205204f1b9744a24d5f996a66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8a2e9386dae424babb10a49f657d348": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac0b8023318745bbb44dffdb4917cd40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae7f8765cdaa4566ba95a3540b586228": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afe94eae80e145609100c29b4224161c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51815149d71749e5acdad988eb9bfdcc",
            "placeholder": "",
            "style": "IPY_MODEL_1fc3d47a107e4411ad8af41b500960e7",
            "value": "466k/466k[00:00&lt;00:00,1.01MB/s]"
          }
        },
        "b63d94b831b64f29a0c8aa0055f3e2e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b99f7b1f5742403289ebba79a2e3a444": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba30f46214f24d9abde5dfcce5d5b5fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d4432105c3e49b982552bc2b4b125c8",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ee3f78323bae40e58b8d35c461e50ed1",
            "value": 231508
          }
        },
        "bda1ffe2957f4a68bd6875c830cacde3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16ff150a77394df1a4482f20b887be8c",
              "IPY_MODEL_831c9bc175fd43dd9e2b1d7b50918933",
              "IPY_MODEL_afe94eae80e145609100c29b4224161c"
            ],
            "layout": "IPY_MODEL_3b776580c37144eeaccfd3ddafd4e456"
          }
        },
        "bf0084c29e9b420b94560a85617a5955": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0c247ab383d4c358be54fb787bce62a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cbbebd3d094848f5aac04848bd8f50d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfdef32ac42a4f4b9979ca9eb407b0f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_452ebf0963c14b83b1f68350f1894abf",
              "IPY_MODEL_ba30f46214f24d9abde5dfcce5d5b5fc",
              "IPY_MODEL_803fa954a89a4add909b30e940134d6d"
            ],
            "layout": "IPY_MODEL_bf0084c29e9b420b94560a85617a5955"
          }
        },
        "d4ad4afb79384be6bea9627fc73abb63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5a6cacf1cb94ba794834e69115fab86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6d2553d11944f5289d0ae9c496b7d46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e22cf89c47ad4f7fa67cf18a9e18e48b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f03b958b44af42a7828a2178f587b324",
            "placeholder": "",
            "style": "IPY_MODEL_b99f7b1f5742403289ebba79a2e3a444",
            "value": "570/570[00:00&lt;00:00,49.7kB/s]"
          }
        },
        "ee3f78323bae40e58b8d35c461e50ed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f03b958b44af42a7828a2178f587b324": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f40e7895e5a648d19ce338a302cd52bb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f736c90796e04d5aa6cfb6e962616030": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}